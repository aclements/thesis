\section{Introduction}
\label{sec:intro}

\XXX[STATUS]{Unchanged from SOSP.  Much of this will stay, but it
  needs to be reorganized and expanded to be more thesis-y.}

\XXX[AC]{We should cite POSIX 2013 \emph{somewhere}.}

The state of the art for evaluating the scalability of multicore software
is to choose a workload, plot performance at varying
numbers of cores, and use tools such as differential
profiling~\cite{mckenney:differential} to
identify scalability bottlenecks.  \XXX[AC]{Should we cite anything
for this?  Is there anything to cite besides our own papers?}
%
This focuses developer effort on real issues, but 
has several drawbacks.
%
Different workloads or higher core counts often exhibit new bottlenecks.
%
It's unclear which bottlenecks are fundamental, so developers may
give up without realizing that
a scalable solution is possible.
%
Finally, this process happens so late in the development process
that design-level solutions such as improved interfaces may be
impractical.

This paper presents a new approach to scalability that
starts at a higher level: the software interface.
%
This makes reasoning about scalability possible before an
implementation exists and before the necessary hardware is available
to measure the implementation's scalability.  It can highlight
inherent scalability problems, leading to alternate interface designs.
And it sets a clear scaling target for the implementation of a
scalable interface.

Scalability is often considered an implementation property, not an
interface property, not least because what scales depends on hardware.
%
However, if we assume a
shared-memory multicore processor with caches kept
coherent by a MESI-like protocol~\cite{papamarcos:mesi},
general scalability arguments are possible.
%
On such processors, a core can scalably read and write data
it has cached exclusively, and scalably read data it has cached
in shared mode. Writing a cache line that was last
read or written by another core is not scalable, however,
since the coherence protocol serializes ownership
changes for each cache line, and because the shared
interconnect may serialize unrelated
transfers~\cite[\S4.3]{boyd-wickizer:thesis}.

We therefore say that a set of operations scales if their implementations
have \emph{conflict-free} memory accesses, where no core writes a
cache line that was read or written by another core.
%
When memory accesses are conflict-free, adding more cores will produce
a linear increase in capacity.
This is not a perfect model of the complex realities of
modern hardware, but it is a good approximation. 

At the core of our approach is this \emph{scalable commutativity rule}: In any
situation where several operations \emph{commute}---meaning
there's no way to distinguish their execution order using the
interface---they have an implementation whose memory accesses
are conflict-free during those operations.
Or, more concisely,
\textbf{whenever interface operations commute, they can be implemented in a way
  that scales.}

Connections between commutativity and concurrency are well
established in the literature.  Previous work, however, has focused on
using commutativity to reason about the safety of executing operations
concurrently (see \cref{sec:related}).  Our work is complementary: we
use commutativity to reason about scalability.


The commutativity rule makes
intuitive sense: when operations commute, their
results (return value and effect on system state) are independent of order.
Hence, communication between commutative operations is
unnecessary, and eliminating it yields conflict-free implementations.
%
This intuitive version of the rule is useful in practice, but
not precise enough to reason
about formally.
%
\Cref{sec:rule} formally defines the commutativity rule and proves
the correctness of the formalized rule.

An important consequence of this presentation is a novel form of
commutativity we call \emph{\SIM\ commutativity}.
%
The usual definition of commutativity (e.g., for algebraic operations)
is so stringent that it rarely applies to the complex, stateful
interfaces common in systems software.
%
\SIM\ commutativity, in contrast, is \emph{state-dependent} and
\emph{interface-based}, as well as \emph{monotonic}.
%
When operations commute in the context of a specific system state,
specific operation arguments, and specific concurrent operations, we
show that an implementation exists that is conflict-free \emph{for that state
  and those arguments and concurrent operations}.
%
This exposes many more opportunities to apply the rule to real
interfaces---and thus discover scalable implementations---than a more
conventional notion of commutativity would.
%
Despite its logical state dependence, \SIM\ commutativity is
interface-based: rather than requiring all operation orders to produce
identical internal states, it requires the resulting states to be
indistinguishable via the interface.
%
\SIM\ commutativity is thus independent of any specific
implementation, enabling developers to apply the rule directly to
interface design.

The commutativity rule leads to a new way to design scalable
software:
%
first, analyze the interface's commutativity, and then design an
implementation that
scales in commutative situations.
%
For example,
consider file creation in a POSIX-like file system. Imagine that
multiple processes create files in the same directory at the same
time. Can the creation system calls be made to scale? Our
first answer was ``obviously not'': the system calls modify the same
directory, so surely the implementation must
serialize access to the directory. But it turns
out these operations commute if the two files have different names
(and no hard or symbolic links are involved) and, therefore, have an
implementation that scales for such names.
One such implementation represents each directory as a hash table
indexed by file name, with an independent lock per bucket,
so that creation of differently named files is conflict-free, barring
hash collisions.
%
Before the rule, we tried to determine if these
operations could scale by analyzing all of the \emph{implementations}
we could think
of.  This process was difficult, unguided, and itself did not scale to
complex interfaces, which
motivated our goal of reasoning about
scalability in terms of interfaces.

Complex interfaces can make it difficult to spot and reason about all
commutative cases even given the rule.  To address this challenge,
\cref{sec:tool} introduces a tool named \tool that automates this
reasoning.  \tool takes an interface model
in the form of a simplified, symbolic implementation, computes precise
conditions under which sets of operations commute, and tests an
implementation for conflict-freedom under these conditions.  This tool can be
integrated into the development process to drive initial design and
implementation, to incrementally improve existing implementations, or to
help developers understand the commutativity of an interface.

This paper demonstrates the value of the commutativity rule and \tool
in two ways.
In \cref{sec:posix}, we explore the commutativity of POSIX
and use this
understanding both to suggest 
guidelines for designing interfaces
whose operations commute and
to propose specific modifications to POSIX
that would allow for greater scalability.

In \cref{sec:topic:model}, we apply \tool to a simplified model of
\pyexpr{len(mscan.calls)} POSIX file system and virtual memory system
calls.
%
From this model,
\tool generates \pyexpr{mscan.ntestcases} tests of commutative
system call pairs, all of which can be made conflict-free
according to the rule.  We use these tests to
guide the implementation of a new research operating system kernel
named \sys.  \sys has a novel virtual memory system
(RadixVM~\cite{clements:radixvm}) and in-memory file
system (named \fs).  \tool determines that \sys is conflict-free for
\pyexpr{mscan.ntestcases - mscan.xv6.shared} of the
\pyexpr{mscan.ntestcases} tests, while Linux is conflict-free
for \pyexpr{mscan.ntestcases - mscan.linux.shared}
tests.  Some of the commutative cases where Linux doesn't scale are important
to applications, such as commutative
\code{mmap}s and creating different files in a shared directory.
\Cref{sec:eval} confirms that commutative conflict-free system calls
translate to better application scalability on an 80-core machine.

% The paper is organized as follows.  \S\ref{sec:related} relates our thinking
% about scalability to previous work. \S\ref{sec:rule} introduces the
% commutativity rule and argues its correctness. \S\ref{sec:posix} applies the
% rule to an OS interface, identifying opportunities for
% commutativity. \S\ref{sec:tool} describes \tool{}.  \S\ref{sec:model} describes
% \fs and how \tool{} drove its implementation. \S\ref{sec:eval} shows that using
% the commutativity rule results in better scalability on real
% hardware. \S\ref{sec:concl} summarizes our conclusions.

% LocalWords:  rule's RCU
