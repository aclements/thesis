\section{Performance evaluation}
\label{sec:eval}

\XXX[STATUS]{Draft v2 ready.  Merged SOSP and \vm evaluations.
  New(ish) intro and discussion sections.  Applied Frans' edits from
  init-228-g69596c0, except for moving more implementation-related
  content to previous chapter.}

Given that nearly all commutative \fs and \vm operations are
conflict-free, in principle, applications built on these operations
should scale perfectly.
%
\Thiscref{sec:eval} confirms this, completing a pyramid whose
foundations were set in \cref{sec:scalability} when we demonstrated
that conflict-free memory accesses scale in most circumstances on real
hardware.
%
\Thiscref{sec:eval} extends these results, showing that complex
operating system calls built on conflict-free memory accesses scale
and that, in turn, applications built on these operations scale.
%
We focus on the following questions:

\begin{CompactItemize}

\item Do conflict-free implementations of commutative operations and
  applications built using them scale on real hardware?

\item Do non-commutative operations limit performance on real
  hardware?

% \item Does optimizing for scalability sacrifice sequential performance?

\end{CompactItemize}

Since real systems cannot focus on scalability to the exclusion of
other performance characteristics, we also consider the balance of
performance requirements by exploring the following question:

\begin{CompactItemize}

\item Can implementations optimized for linear scalability of
  commutative operations also achieve competitive sequential
  performance, reasonable (albeit sub-linear) scalability of
  non-commutative operations, and acceptable memory use?

\end{CompactItemize}


To answer these questions, we use \sys.
In addition to the operations analyzed in \cref{sec:sv6}, we scalably
implemented
other commutative operations (e.g., \code{posix_spawn})
and many of the modified POSIX APIs from
\cref{sec:posix}.
%
All told, \sys
totals \pyexpr{const["xv6-loc"]["all"]} lines of code, including user
space and library code.
%
Using \sys, we evaluate two microbenchmarks and one application
benchmark focused on file system operations, and three microbenchmarks
and one application benchmark focused on virtual memory operations.


\subsection{Experimental setup}
\label{sec:topic:ben}


We ran experiments on an 80-core machine with eight 2.4~GHz 10-core
Intel E7-8870 chips and 256~GB of RAM (detailed earlier in
\cref{fig:machines}).
%
When varying the number of
cores, benchmarks enable whole sockets at a time, so each 30~MB
socket-level L3 cache is shared by exactly 10~enabled cores.
We also report single-core numbers for
comparison, though these are expected to be higher because without
competition from other cores in the socket, the one
core can use the entire 30~MB cache.

We run all benchmarks with the hardware prefetcher disabled because we
found that it often prefetched contended cache lines to cores that did
not ultimately access those cache lines, causing significant
variability in our benchmark results and hampering our efforts to
precisely control sharing.  We believe that, as large multicores and
highly parallel applications become more prevalent, prefetcher
heuristics will likewise evolve to not induce this false sharing.

As a performance baseline, we compare against the same
benchmarks running on Linux~3.5.7 from Ubuntu Quantal.
%
All benchmarks compile and run on Linux and \sys without modifications.
%
Direct comparison is difficult because
Linux implements many features \sys does not, but this comparison
confirms \sys's sequential performance is sensible.
% \XXX[AC]{Different version from mtrace, which is a little awkward.}
% %
% In the virtual memory benchmarks, we additionally compare against
% Linux with the Bonsai VM system~\cite{clements:bonsai} (based on
% kernel version 2.6.37).
% %
% Bonsai implements a \code{pagefault} operation that is usually
% conflict-free with commutative \code{pagefault}s, but still serializes
% \code{mmap} and \code{munmap} operations.

We run each benchmark three times and report the mean.  Variance from
the mean is always under 5\% and typically under 1\%.
% \XXX[AC]{Except mailbench with regular APIs on 80 cores, where
% something clearly went bonkers, and a few VM microbenchmark points
% on Linux and Bonsai, but they're so collapsed that mean variance
% doesn't mean much.}

\subsection{File system microbenchmarks}
\label{sec:eval:fs-microbenchmarks}

% Many interfaces provide stricter or more complex semantics than
% generally required by applications.  \code{fstat}, for example, combines
% several return values, including properties like a file's
% link count, while applications typically only need one or two of these
% properties, such as the file size or modification time.  Such interfaces
% often have limited commutativity, where slightly modified interfaces
% that better align with application needs may commute in more situations.
% \code{fstat} does not commute with \code{link} on the same inode because
% \code{link} modifies the link count that \code{fstat} returns, but if an
% application could request only, say, the file size, the resulting
% interface would commute with \code{link}.

% We call such cases, where operations do not commute according to the
% specification but weaker and more widely commutative semantics suffice
% for many applications, \emph{needless non-commutativity}.
% \XXX[AC]{Avoid ``needless non-commutativity.''  The point of the
% commutative versions of the benchmarks is just to verify that it's the
% non-commutativity limiting scalability.}

% In this section, we explore the impact of non-commutative interfaces on
% scalability by examining the scalability of some of the needlessly
% non-commutative POSIX interfaces discussed in
% \cref{sec:posix}. \XXX[FK]{I don't think we need this reference to
% section 6, and we could do without section 6, and turning it into a
% future work and discussion section.}

Each file system benchmark has
two variants, one that uses standard, non-commutative POSIX APIs and
another that accomplishes the same task using the modified, more broadly
commutative APIs from \cref{sec:posix}.
%
By benchmarking the standard interfaces against
their commutative counterparts, we can isolate the cost of
non-commutativity and also examine the scalability of
conflict-free implementations of commutative operations.

% We examine three different classes of
% non-commutativity: statbench exercises \code{fstat}, which combines
% several operations into one; openbench exercises file descriptor
% allocation, which has process-wide invariants; and sockbench exercises
% local sockets, which have strict ordering requirements.

\paragraph{\cmd{statbench}.} In general, it's difficult to argue that an
implementation of a
non-commutative interface achieves the best possible scalability for
that interface and that no implementation could scale better.  However,
in limited cases, we can do exactly this.  We start with \cmd{statbench},
which measures the scalability of \code{fstat} with respect to
\code{link}.  This benchmark creates a single file that $n/2$ cores
repeatedly \code{fstat}. The other $n/2$ cores repeatedly
\code{link} this file to a new, unique file name, and then \code{unlink}
the new file name.  As discussed in \cref{sec:posix}, \code{fstat} does not
commute with \code{link} or \code{unlink} on the same file because
\code{fstat} returns the link count.  In practice,
applications rarely invoke \code{fstat} to get the link count, so \sys
introduces \code{fstatx}, which allows applications to request specific
fields (a similar system call has been proposed for
Linux~\cite{linux:xstat}).

\XXX[AC]{Mention that commutative statbench helps verify our
disjoint-access parallelism assertion on real hardware.}

\newcounter{mysubfigure}[figure]
\renewcommand{\themysubfigure}{\thefigure(\alph{mysubfigure})}

\begin{figure*}
  \centering
  % Make subfigure labels refer to correct figure
  \stepcounter{figure}
  % Top-align the two graphs
  \tikzset{gnuplot/.append style={baseline=(current bounding box.north)}}
  \input{graph/linkbench.tex}
  \refstepcounter{mysubfigure}
  \label{fig:linkbench}
  \hspace{-.05in}
  \input{graph/fdbench.tex}
  \hspace{-0.2in}
  \refstepcounter{mysubfigure}
  \label{fig:fdbench}
  \addtocounter{figure}{-1}
  %
  \splitcaption{File system microbenchmark throughput}{in operations
    per second per core with
    varying core counts on \sys.
    The blue dots indicate single core Linux
    performance for comparison.}
\end{figure*}

% \begin{figure}
%   \centering
%   \input{graph/linkbench.tex}
%   \caption{\code{fstat} throughput with $n/2$ cores running \code{fstat}
%     and $n/2$ cores running \code{link}/\code{unlink}.}
%   \label{fig:linkbench}
% \end{figure}

We run \cmd{statbench} in two modes: one mode uses \code{fstat}, which does
not commute with the \code{link} and \code{unlink} operations performed
by the other threads, and the other mode uses \code{fstatx} to request
all fields except the link count, an operation that \emph{does} commute
with \code{link} and \code{unlink}.  We use a \refcache scalable
counter for the link count so that the
\code{link}s and \code{unlink}s are conflict-free, and place it on
its own cache line to avoid false sharing.
\Cref{fig:linkbench} shows the results.  With the commutative
\code{fstatx}, \cmd{statbench} scales perfectly for both \code{fstatx} and
\code{link}/\code{unlink} and experiences zero L2 cache
misses in \code{fstatx}.  On the other hand, the traditional
\code{fstat} scales poorly and the conflicts induced by \code{fstat}
impact the scalability of the threads performing \code{link} and
\code{unlink}.

%This is no implementation fluke. 
To better
isolate the difference between \code{fstat} and \code{fstatx}, we run
\cmd{statbench} in a
third mode that uses \code{fstat}, but represents the link count
using a simple shared counter instead of \refcache.  In this mode, \code{fstat}
performs better at low core counts, but \code{fstat}, \code{link}, and
\code{unlink} all suffer at higher core counts.
%
With a shared link count, each \code{fstat}
call experiences exactly one L2 cache miss (for the cache line
containing the link count), which means this is the most scalable that
\code{fstat} can possibly be in the presence of concurrent \code{link}s
and \code{unlink}s.  Yet, despite sharing only a single cache line, the
seemingly innocuous conflict arising from the non-commutative
interface limits the
implementation's scalability.  One small tweak to make the operation
commute by omitting \code{st_nlink} eliminates the barrier to scaling,
demonstrating that even an optimal implementation of a non-commutative
operation can have severely limited scalability, underscoring the
results of \cref{sec:scalability}.

In the case of \code{fstat}, optimizing for scalability sacrifices some
sequential performance.  Tracking the link count with \refcache
(or some scalable counter) is necessary to make \code{link} and
\code{unlink} scale linearly, but requires \code{fstat} to reconcile the
distributed link count to return \code{st_nlink}.  The exact overhead
depends on the core count, which determines the number of \refcache
caches, but with 80 \refcache caches, \code{fstat} is \pyexpr{times(
  mean(linkbench.filter(("iv.st_nlink",True),("iv.stats",1),("iv.FS_NLINK_REFCOUNT","refcache::"))["dv.cycles/stat"]),
  mean(linkbench.filter(("iv.st_nlink",True),("iv.stats",1),("iv.kernel","Linux"))["dv.cycles/stat"]))}
more expensive than on Linux.  \XXX[AC]{Haven't tried optimizing this.}
%
In contrast, \code{fstatx} can avoid this overhead unless the caller
requests link counts; like \code{fstat} with a shared count, it
performs similarly to Linux's \code{fstat} on a single core.
%\pyexpr{int(mean(linkbench.filter(("iv.st_nlink",True),("iv.stats",1),("iv.FS_NLINK_REFCOUNT","::"))["dv.cycles/stat"]))}~cycles
% Above 20~cores, the shared link count and \refcache link count
% implementations of \code{fstat} scale similarly.

\paragraph{\cmd{openbench}.} \Cref{fig:fdbench} shows the results
of \cmd{openbench}, which stresses the file descriptor allocation performed by
\code{open}.  In \cmd{openbench}, $n$ threads concurrently \code{open} and
\code{close} per-thread files.  These calls do not commute because each
\code{open} must allocate the lowest unused file
descriptor in the process.  For many applications, it suffices to return
any unused file descriptor (in which case the \code{open} calls commute),
so \sys adds an \code{O_ANYFD} flag to \code{open}, which it implements
using per-core partitions of the FD space.  Much like
\cmd{statbench}, the standard, non-commutative \code{open} interface limits
\cmd{openbench}'s scalability, while \cmd{openbench} with \code{O_ANYFD} scales
linearly.

Furthermore, there is no performance penalty to
\fs's \code{open}, with or without \code{O_ANYFD}: at one core, both
cases perform identically and outperform Linux's \code{open} by
\pyexpr{percent(
  mean(fdbench.filter(("iv.cores",1),("iv.kernel","xv6"),("iv.any_fd",False))["dv.opens/sec"])
  /mean(fdbench.filter(("iv.cores",1),("iv.kernel","Linux"))["dv.opens/sec"])
  -1)}.
Some of the performance difference is because \sys doesn't implement things like
permissions checking, but much of Linux's overhead comes from locking
that \fs avoids.

% \begin{figure}
%   \centering
%   \input{graph/fdbench.tex}
%   \caption{\code{open} throughput with varying FD allocation policies.}
%   \label{fig:fdbench}
% \end{figure}

\begin{comment}
\paragraph{sockbench.}

\Cref{fig:sockbench} shows the results of sockbench, which
stresses local sockets.  In sockbench $n$ client processes repeatedly
send a 1-byte message over a local socket to $n$ server processes and
wait for a 1-byte response. The clients send the 1 byte message over a
datagram socket that is shared among all servers.  The POSIX API doesn't
require that datagram messages be delivered in order but most operating
systems do enforce this ordering because a single queue for a socket is
the most straightforward implementation.  This unnecessary ordering,
however, makes \code{sendto} invocations on a datagram socket needlessly
non-commutative.

\sys allows for out of order delivery of datagram messages, making
invocations to \code{sendto} commute with each other.  \sys takes
advantage of this commutativity to achieve scalability as follows. When
\sys notices that several cores are receiving from a shared datagram
socket, it partitions the socket among the cores.  A sending core puts a
message into its local partition of the socket, unless its partition is
full.  If the partition is full, \sys invokes a scalable load balancing
algorithm to deliver the message into another partition.

As the results in \Cref{fig:sockbench} show, \sys scales
perfectly, because each pair of a client and a server communicate
through its local partition of the datagram socket.  Thus, cores don't
need to share any cache lines, and \sys scales perfectly.  Linux scales
until a small number of cores, and then collapses because of a contended
spin lock protecting the in-kernel queue for the datagram socket.
\sys's scalability doesn't come at the cost of single-core performance;
in fact, \sys's single core performance is better than Linux.

If an application performs its own load balancing, it could implement
\sys's approach at the application level by setting up $n$ datagram
sockets, for each pair of a client and a server.  With this setup
invocations to \code{sendto} commute because they involve different
datagram sockets.  Unfortunately, today this setup does not result in
better scalability on Linux.  The line labeled ``$n$ datagram sockets''
shows better scalability than the line ``1 datagram socket'', but it
also collapses. At 20 cores, a spin lock protecting the name lookup in
\code{sendto} becomes contended.

The application could perform the name lookup once by a setting up a
stream socket at the beginning, and then using \code{send} to
communicate.  This setup results in better scalability (see the line
labeled ``Linux with $n$ streams''). But, in this setup, a spin
lock in the scheduler becomes a bottleneck (\XXX[FK]{double check}).
Clearly, Linux developers could remove these bottlenecks.  What is nice
about our approach is that the commutativity rule makes clear that these
locks can be removed and that \tool{} can catch these non-scalable
invocations that should be scalable.  \XXX[FK]{We should mention
somewhere that we have a model for unordered and ordered sockets.}

\begin{figure}
  \centering
  \input{graph/usocket.tex}
  \caption{Scalability of $n$ clients concurrently sending and receiving 1
    byte messages to/from $n$ server  processes.}
  \label{fig:sockbench}
\end{figure}
\end{comment}

%     lazy unmap [doing more than one thing]
%     thread-level mmap?
%     stat vs. fstat (name lookup)

\subsection{File system application performance}
\label{sec:eval:app}

We perform a similar experiment using a simple mail server to
produce a file system workload more representative of a real
application.  The mail server uses a sequence of separate, communicating
processes, each with a specific task, roughly like qmail~\cite{qmail}.
\cmd{mail-enqueue} takes a mailbox name and a single message on
standard in, writes the message and the envelope to two files in a
mail queue directory, and notifies the queue manager by writing the
envelope file
name to a Unix domain datagram socket.  \cmd{mail-qman} is a long-lived
multithreaded process where each thread reads from the notification
socket, reads the envelope information, opens the queued message, spawns
and waits for the delivery process, and then deletes the queued message.
Finally, \cmd{mail-deliver} takes a mailbox name and a single message
on standard in and delivers the message to the appropriate Maildir.
The benchmark models a mail client with $n$ threads that continuously
deliver email by spawning and feeding \cmd{mail-enqueue}.

As in the microbenchmarks, we run the mail server in two configurations:
in one we use lowest FD, an order-preserving socket for queue
notifications, and \code{fork}/\code{exec} to spawn helper processes; in
the other we use \code{O_ANYFD}, an unordered notification socket, and
\code{posix_spawn}, all as described in \cref{sec:posix}.
%\cmd{openbench} explored the limitations of lowest
%FD.
For queue notifications, we use a Unix domain datagram socket.
\sys implements this with a single shared queue in ordered mode
%
In unordered mode, \sys uses load-balanced per-core message queues.
Load balancing only triggers when a core attempts to read from an
empty queue, so operations on unordered sockets are conflict-free as
long as consumers don't outpace producers.
%
Finally, because \code{fork} commutes with essentially no other
operations in the same process,
\sys implements \code{posix_spawn} by constructing the new process image
directly and building the new file
table. This implementation is conflict-free with most other operations,
including operations on
\code{O_CLOEXEC} files (except those specifically \code{dup}ed into the
new process).

\begin{figure}
  \centering
  \input{graph/mailbench.tex}
  %
  \splitcaption{Mail server benchmark throughput.}{The blue dot
    indicates single core Linux performance for comparison.}
  \label{fig:mailbench}
\end{figure}

\Cref{fig:mailbench} shows the resulting scalability of these two
configurations.  Even though the mail server performs a much broader mix
of operations than the microbenchmarks and doesn't focus solely on
non-commutative operations, the results are quite similar.
Non-commutative operations cause the benchmark's throughput to collapse
at a small number of cores, while the configuration that uses
commutative APIs achieves \pyexpr{times(
  mean(mailbench.filter(("iv.cores",80),("iv.alt","all"),("iv.kernel","xv6"))["dv.messages/sec"]),
  mean(mailbench.filter(("iv.cores",10),("iv.alt","all"),("iv.kernel","xv6"))["dv.messages/sec"]))}
scalability from 1~socket
(10~cores) to 8~sockets.
%
% In the non-commutative case, mailbench on \sys slightly outperforms
% Linux.
%
\XXX[AC]{We could also make the point that, the commutative APIs
outperform the non-commutative APIs on one core, in addition to
out-scaling them.}

\XXX[AC]{In the commutative case, our scalability is currently limited
by the growing chains in the fixed-size dcache hash table of the
Maildir.  A resizable hash table would probably help.}

\XXX[AC]{In the non-commutative case, the top problem is fork by far.
However, with \code{posix_spawn} instead of fork, we spend all of our
time in \code{posix_spawn}, which scales but is slow.  If its
\emph{sequential} performance were better, the other things mailbench
does would matter more.}

% \begin{figure}
%   \centering
%   \input{graph/mailbench.tex}
%   \caption{Throughput of $n$ mail agents sending messages to a mail
%     server, which delivers them to a Maildir.}
%   \label{fig:mailbench}
% \end{figure}

\begin{comment}
\begin{figure}
  \centering
  \input{graph/forktest.tex}
  \caption{Scalability of $n$ cores forking and exiting a process on xv6
    and Linux.}
  \label{fig:forktest}
\end{figure}
\end{comment}


\subsection{Virtual memory microbenchmarks}

To understand the scalability and performance of \sys's \vm virtual
memory system, we use three microbenchmarks, each of which exercises a
specific pattern of address space usage.

As in the earlier benchmarks, we compare \vm against Linux~3.5.7.  We
additionally compare against the Bonsai VM
system~\cite{clements:bonsai} (which is based on Linux~2.6.37).
%
As discussed in \cref{sec:topic:linux-coarse}, in the Linux kernel
\code{mmap}, \code{munmap}, and \code{pagefault} all acquire a
per-address space lock.  This serializes \code{mmap} and \code{munmap}
operations.  Linux's \code{pagefault} acquires the lock in shared
mode, allowing \code{pagefault}s to proceed in parallel, but acquiring
the address space lock in shared mode still induces conflicts on the
cache line storing the lock.
%
Bonsai modifies the Linux virtual memory system so that
\code{pagefault}s do not acquire this lock.  This makes most
commutative \code{pagefault}s conflict-free in Bonsai, though Bonsai
does not modify the locking behavior of \code{mmap} and \code{munmap},
so all \code{mmap} and \code{munmap} operations on the same address
space conflict.

\Cref{fig:vm-tput} shows the throughput of our three microbenchmarks
on \sys, Bonsai, and Linux.
%
For consistency, we measure the number of pages written per second per
core in all three benchmarks.
%
Because \sys uses per-core page tables, each of these writes
translates into a page fault, even if the page has already been
faulted by another core.
%
Linux and Bonsai incur fewer page faults than \sys for the pipeline
and global microbenchmarks because all cores use the same page table.

\begin{figure*}
  \centering
    \stepcounter{figure}
    \input{graph/vm-local-tput.tex}
    \refstepcounter{mysubfigure}
    \label{fig:vm-tput:local}
    \hspace{-.25in}
    \input{graph/vm-pipeline-tput.tex}
    \refstepcounter{mysubfigure}
    \label{fig:vm-tput:pipeline}
    \hspace{-.25in}
    \input{graph/vm-global-tput.tex}
    \refstepcounter{mysubfigure}
    \label{fig:vm-tput:global}
    \addtocounter{figure}{-1}
  %
  \splitcaption{Virtual memory microbenchmark throughput}{in page
    writes per second per core with varying core counts.}
  \label{fig:vm-tput}
\end{figure*}

\paragraph{\cmd{vmlocal}.} The \cmd{vmlocal} microbenchmark exercises
completely disjoint address space usage.
%
In \cmd{vmlocal}, each thread \code{mmap}s a single page in the shared
address space, writes to the page (invoking \code{pagefault}), and
then \code{munmap}s the page.
%
Because each thread maps a page at a different virtual address, all
operations performed by \cmd{vmlocal} commute.

Many concurrent memory allocators use per-thread memory pools that
specifically optimize for thread-local allocations and exhibit this
pattern of address space manipulation~\cite{jemalloc,tcmalloc}.
However, such memory allocators typically map memory in large batches
and conservatively return memory to the operating system to avoid
burdening on the virtual memory system.
%
Our microbenchmark does the opposite, using 4~KB regions to maximally
stress the VM system.

The \cmd{vmlocal} microbenchmark scales linearly on \sys.
%
While this benchmark does incur cache misses, none are conflict misses
and none require cross-core communication.
%
Regardless of the number of cores, we observe about 75 L2 cache misses
per iteration and about 50 L3 cache misses, almost all a result of
page zeroing.
%
None of these require cross-socket communication as all are satisfied
from the core's local DRAM, which is consistent with \tool's
determination that these operations are conflict-free.
%
Likewise, because \sys can track remote TLBs precisely, the \cmd{vmlocal}
microbenchmark sends no TLB shootdowns.
%
Because these operations are conflict-free---there is no lock
contention, a small and fixed number of cache misses, no remote DRAM
accesses, and no TLB shootdowns---the time required to \code{mmap},
\code{pagefault}, and \code{munmap} is constant regardless of the
number of cores.

Linux and Bonsai, on the other hand, slow down as we add more cores.
%
This is not unexpected: Linux acquires the address space lock three
times per iteration and Bonsai twice per iteration, effectively
serializing the benchmark.
% \XXX[AC]{Non-scalable locks are the reason for slow down beyond
% serialization.}
%
\sys also demonstrates good sequential performance: at one core,
\sys's performance is within 8\% of Linux, and it is likely this could
be improved.

\paragraph{\cmd{vmpipeline}.} The \cmd{vmpipeline} benchmark captures
the pattern of streaming or pipeline communication, such as a
\emph{map} task communicating with a \emph{reduce} task in
MapReduce~\cite{dean:mapreduce}.
%
In \cmd{vmpipeline}, each thread \code{mmap}s a page of memory, writes to
the page, and passes the page to the next thread in sequence, which
also writes to the page and then \code{munmap}s it.
%
The operations performed by neighboring cores do not commute and their
implementation is not conflict-free.
%
However, the operations of non-neighboring cores do commute, so unlike
the non-commutative cases in the file system benchmarks, increasing
the number of cores in \cmd{vmlocal} increases the number of conflicted
cache lines without increasing the number of cores conflicting on each
cache line.
%
As a result, \cmd{vmpipeline} still scales well on \sys, but not linearly.
%
We observe similar cache miss rates as \cmd{vmlocal}, but \cmd{vmpipeline} induces
cross-socket memory references for pipeline synchronization, returning
freed pages to their home nodes when they are passed between sockets,
and cross-socket shootdown IPIs.
% 0.07 cache lines moved per iteration
For Linux and Bonsai, \cmd{vmpipeline} is almost identical to \cmd{vmlocal} except
that it writes twice to each page; hence we see almost identical
performance, scaled up by a factor of two.
%
Again, \sys's single core performance is within 8\% of Linux.

% TLB shootdowns/iteration is fixed at 1.2, but cycles/TLB shootdown
% grows from ~7000 at 10 cores to 37000 at 80 cores (not enough to add
% up to the cycles/iteration growth).  cycles/munmap tracks this.
% cycles/mmap is relatively constant.  cycles/alloc page fault also
% grows from ~6000 at 10 cores to ~12000 at 80 cores.

\paragraph{\cmd{vmglobal}.} Finally, \cmd{vmglobal} simulates a widely shared
region such as a memory-mapped library or a shared data structure like
a hash table.
%
In \cmd{vmglobal}, each thread \code{mmap}s a 64~KB part of a large region
of memory, then all threads access all of the pages in the large
region in a random order.
%
These operations commute within each phase---all \code{mmap}s are to
non-overlapping regions and \code{pagefault}s always commute---but not
between phases.

\cmd{Vmglobal} scales well on \sys, despite being conceptually poorly
suited to \sys's per-core page tables and targeted TLB shootdown.  In
this benchmark, \sys performance is limited by the cost of TLB
shootdowns: at 80 cores, delivering shootdown IPIs to the other 79
cores and waiting for acknowledgments takes nearly a millisecond.
% 1.8 million cycles
However, at 80~cores, the shared region is 20~MB, so this cost is
amortized over a large number of page faults.
%
Linux and Bonsai perform better on this benchmark than on \cmd{vmlocal} and
\cmd{vmpipeline} because it has a higher ratio of page faults to \code{mmap}
and \code{munmap} calls, but they still fail to scale.


\subsection{Virtual memory application benchmark}

To evaluate the impact of \vm on application performance, we use
Metis, a high-performance single-server multithreaded MapReduce
library, to compute a word position index from a 4~GB in-memory text
file~\cite{dean:mapreduce,metis:tr}.
%
Metis exhibits all of the sharing patterns exercised by the
microbenchmarks: it uses core-local memory, it uses a globally shared
B+-tree to store key-value pairs, and it also has pairwise sharing of
intermediate results between \emph{map} tasks and \emph{reduce} tasks.
%
Metis also allows a direct comparison with the Bonsai virtual memory
system~\cite{clements:bonsai}, which used Metis as its main benchmark.

By default Metis uses the Streamflow memory
allocator~\cite{schneider:streamflow}, which is designed to minimize
pressure on the VM system, but nonetheless suffers from contention in
the VM system when running on Linux~\cite{clements:bonsai}.  Previous
systems that used this library avoided contention for in-kernel locks
by using super pages and improving the granularity of the super page
allocation lock in Linux~\cite{boyd-wickizer:scaling}, or by having
the memory allocator pre-allocate all memory upfront~\cite{metis:tr}.
While these workarounds do allow Metis to scale on Linux, we wanted to
focus on the root scalability problem in the VM system rather than the
efficacy of workarounds and to eliminate compounding factors from
differing library implementations, so we use a custom allocator on
both Linux and \sys designed specifically for Metis.  In contrast with
general-purpose memory allocators, this allocator is simple and
designed to have no internal contention: memory is mapped in
fixed-sized blocks, free lists are exclusively per-core, and the
allocator never returns memory to the OS.

Two factors determine the scalability of Metis: conflicts between
concurrent \code{mmap}s during the \emph{map} phase and conflicts
between concurrent \code{pagefault}s during the \emph{reduce} phase.
%
If the memory allocator uses a large allocation unit, Metis
can avoid the first source of contention by minimizing the number of
\code{mmap} invocations.
%
Therefore, we measure Metis using two different allocation units: 8~MB
to stress \code{pagefault} and 64~KB to stress \code{mmap}.
%
At 80 cores, Metis invokes \code{mmap} 5,987 times in the 8~MB
configuration, and 572,292 in the 64~KB configuration.
%
In both cases, it invokes \code{pagefault} approximately 12~million
times, where 70\% of these page faults cause it to allocate new
physical pages and the rest bring pages already faulted on another
core in to the per-core page tables.

\begin{figure}
  \centering
  \input{graph/wrmem.tex}
  %
  \splitcaption{Metis application scalability}{for different VM
    systems and allocation unit sizes.}
  \label{fig:metis}
\end{figure}

\XXX[AC]{Metis's scalability on \sys for 64~KB units is limited by
  umalloc being dumb, not by \vm as far as I can tell.}

\Cref{fig:metis} shows how Metis scales for the inverse indexing
application for the three VM systems.
%
Metis scales poorly on Linux in both configurations, spending most of
its time at high core counts in the virtual memory system acquiring
the address space lock rather than performing useful computation.
%
This is true even in the \code{pagefault}-heavy configuration because,
while \code{pagefault}s run in parallel on Linux, acquiring the
address space lock in shared mode induces cache line conflicts.

Metis on \sys scales comparatively well with both large and small
allocation sizes.
%
For the 8~MB \code{pagefault}-heavy configuration, both \sys and
Bonsai scale near-linearly, both as a result of conflict-free
\code{pagefault} implementations.
%
Furthermore, in this configuration \sys and Bonsai perform
similarly---\sys is $\sim5\%$ slower than Bonsai at all core
counts---suggesting that there is little or no sequential performance
penalty to \vm's very different design.  It's likely we could close
this gap with further work on the sequential performance of \sys.
%
Unlike Bonsai, \sys achieves conflict-free \code{mmap} and
\code{munmap} in addition to conflict-free \code{pagefault}s, enabling
it to out-scale Bonsai in the \code{mmap}-heavy 64~KB configuration.


\subsection{Memory overhead}
\label{sec:eval:memory}

Thus far, we've considered two measures of throughput: scalability and
sequential performance.  \Thiscref{sec:eval:memory} turns to memory
overhead, another important performance metric.

While \fs's data structures closely resemble those of traditional Unix
kernels, \vm's scalability depends on a less-compact representation of
virtual memory than a traditional binary tree of memory regions and
per-core page tables.

To quantify the memory overhead of \vm's radix tree, we took snapshots
of the virtual memory state of various memory-intensive applications
and servers running on Linux and measured the space required to
represent the address space metadata in both Linux and \vm.
%
Linux uses a single object to represent each contiguous range of
mapped memory (a \emph{virtual memory area} or VMA), arranged in a
red-black tree, which makes its basic address space layout metadata
very compact.
%
As a result, Linux must store information about the physical pages
backing mapped virtual pages separately, which it cleverly does in the
hardware page table itself, making the hardware page table a crucial
part of the address space metadata.
%
\vm, on the other hand, stores both OS-specific metadata and physical
page mappings together in the radix tree.
%
This makes the radix tree larger than the equivalent VMA tree, but
means \vm can freely discard memory used for per-core hardware page
tables.

\begin{table}
  \centering
  \figureversion{tab}
  \begin{tabular}{l r r r r@{ }r} \toprule
    & & \multicolumn{2}{c}{Linux} & \multicolumn{2}{c}{Radix tree} \\
    & RSS & VMA tree & Page table & \multicolumn{2}{c}{(rel. to Linux)} \\
    \midrule
    Firefox & \pyexpr{vmsize_row("firefox-10.0.6-used")} \\
    Chrome & \pyexpr{vmsize_row("chrome-used")} \\
    Apache & \pyexpr{vmsize_row("eurosys-apache")} \\
    MySQL & \pyexpr{vmsize_row("eurosys-mysql")} \\
    \bottomrule
  \end{tabular}
  %
  \splitcaption{Memory usage for alternate VM representations.}{RSS
    (resident set size) gives the size of the memory mapped and
    faulted by the application.  The other columns give the size of
    the address space metadata structures used by Linux and \vm.}
  \label{tab:memuse}
\end{table}

\Cref{tab:memuse} summarizes the memory overhead of these two
representations for four applications: the Firefox and Chrome web
browsers, after significant use, and the Apache web server and MySQL
database server used by the EuroSys 2013 paper submission web site.
%
Compared to each application's resident set size (the memory directly
allocated by the application), the radix tree incurred at most a
3.7\% overhead in total memory footprint.


\subsection{Discussion}

\Thiscref{sec:eval} completes our trajectory from theory to practice.
%
The benchmarks herein have demonstrated that commutative operations
can be implemented to scale, confirming the scalable commutativity
rule for complex interfaces and real hardware and validating the
designs and design methodologies set out in \cref{sec:sv6}.
%
Several of these benchmarks have also demonstrated the necessity of
commutativity and conflict-freedom for scalability by showing that
even a single contended cache line in a complex operation can severely
limit scalability.
%
Furthermore, all of this can be accomplished at little cost to
sequential performance or memory use.

% LocalWords:  microbenchmark microbenchmarks vmlocal vmpipeline
% LocalWords:  vmglobal Metis
