\section{Performance evaluation}
\label{sec:eval}

\XXX[STATUS]{Merged SOSP and \vm evaluations.  Draft almost ready.}

\XXX![AC]{Make graph style match \cref{sec:scalability}.}
\XXX![AC]{Fix overfull width for three column graphs.}
\XXX[AC]{Make sure sections explicitly tie in to evaluation
  questions.}

The previous \lcnamecref{sec:sv6} showed that \fs and \vm achieve
conflict-freedom for nearly all commutative operations, which in
principle should result in perfect scalability for these operations.
%
\Thiscref{sec:eval} confirms this, completing a pyramid whose
foundations were set in \cref{sec:scalability} when we demonstrated
that conflict-free memory accesses scale in most circumstances on real
hardware.
%
\Thiscref{sec:eval} extends these results, showing that complex
operating system calls built on conflict-free memory accesses scale
and that, in turn, applications built on these operations scale.
%
We focus on the following questions:

\begin{CompactItemize}

\item Do conflict-free implementations of commutative operations and
  applications built using them scale on real hardware?

\item Do non-commutative operations limit performance on real
  hardware?

% \item Does optimizing for scalability sacrifice sequential performance?

\end{CompactItemize}

Since real systems cannot focus on scalability to the exclusion of
other performance characteristics, we also consider the balance of
performance requirements by exploring the following question:

\begin{CompactItemize}

\item Can implementations optimized for linear scalability of
  commutative operations also achieve competitive sequential
  performance, reasonable (albeit sub-linear) scalability of
  non-commutative operations, and acceptable memory use?

\end{CompactItemize}


To answer these questions, we use \sys.
In addition to the operations analyzed in \cref{sec:sv6}, we scalably
implemented
other commutative operations (e.g., \code{posix_spawn})
and many of the modified POSIX APIs from
\cref{sec:posix}.
%
All told, \sys
totals \pyexpr{const["xv6-loc"]["all"]} lines of code, including user
space and library code.
%
Using \sys, we evaluate two microbenchmarks and one application
benchmark focused on file system operations, and three microbenchmarks
and one application benchmark focused on virtual memory operations.


\subsection{Experimental setup}
\label{sec:topic:ben}


We ran experiments on an 80-core machine with eight 2.4~GHz 10-core
Intel E7-8870 chips and 256~GB of RAM (detailed earlier in
\cref{fig:machines}).
%
When varying the number of
cores, benchmarks enable whole sockets at a time, so each 30~MB
socket-level L3 cache is shared by exactly 10~enabled cores.
We also report single-core numbers for
comparison, though these are expected to be higher because without
competition from other cores in the socket, the one
core can use the entire 30~MB cache.

We run all benchmarks with the hardware prefetcher disabled because we
found that it often prefetched contended cache lines to cores that did
not ultimately access those cache lines, causing significant
variability in our benchmark results and hampering our efforts to
precisely control sharing.  We believe that, as large multicores and
highly parallel applications become more prevalent, prefetcher
heuristics will likewise evolve to not induce this false sharing.

As a performance baseline, we compare against the same
benchmarks running on Linux~3.5.7 from Ubuntu Quantal.
%
All benchmarks compile an run on Linux and \sys without modifications.
%
Direct comparison is difficult because
Linux implements many features \sys does not, but this comparison
confirms \sys's sequential performance is sensible.
\XXX[AC]{Different version from mtrace, which is a little awkward.}
%
In the virtual memory benchmarks, we additionally compare against
Linux with the Bonsai VM system~\cite{clements:bonsai} (based on
kernel version 2.6.37).
%
Bonsai implements a \code{pagefault} operation that is usually
conflict-free with commutative \code{pagefault}s, but still serializes
\code{mmap} and \code{munmap} operations.

\subsection{File system microbenchmarks}
\label{sec:eval:fs-microbenchmarks}

% Many interfaces provide stricter or more complex semantics than
% generally required by applications.  \code{fstat}, for example, combines
% several return values, including properties like a file's
% link count, while applications typically only need one or two of these
% properties, such as the file size or modification time.  Such interfaces
% often have limited commutativity, where slightly modified interfaces
% that better align with application needs may commute in more situations.
% \code{fstat} does not commute with \code{link} on the same inode because
% \code{link} modifies the link count that \code{fstat} returns, but if an
% application could request only, say, the file size, the resulting
% interface would commute with \code{link}.

% We call such cases, where operations do not commute according to the
% specification but weaker and more widely commutative semantics suffice
% for many applications, \emph{needless non-commutativity}.
% \XXX[AC]{Avoid ``needless non-commutativity.''  The point of the
% commutative versions of the benchmarks is just to verify that it's the
% non-commutativity limiting scalability.}

% In this section, we explore the impact of non-commutative interfaces on
% scalability by examining the scalability of some of the needlessly
% non-commutative POSIX interfaces discussed in
% \cref{sec:posix}. \XXX[FK]{I don't think we need this reference to
% section 6, and we could do without section 6, and turning it into a
% future work and discussion section.}

Each file system benchmark has
two variants, one that uses standard, non-commutative POSIX APIs and
another that accomplishes the same task using the modified, more broadly
commutative APIs from \cref{sec:posix}.
%
By benchmarking the standard interfaces against
their commutative counterparts, we can isolate the cost of
non-commutativity and also examine the scalability of
conflict-free implementations of commutative operations.

We run each benchmark three times and report the mean.  Variance from
the mean is always under 4\% and typically under 1\%.  \XXX[AC]{Except
mailbench with regular APIs on 80 cores, where something clearly went
bonkers.}
%
\XXX![AC]{This is true of mailbench, Metis for all but \sys, 8~MB at
  20 cores, and almost all points in the VM microbenchmark.}

% We examine three different classes of
% non-commutativity: statbench exercises \code{fstat}, which combines
% several operations into one; openbench exercises file descriptor
% allocation, which has process-wide invariants; and sockbench exercises
% local sockets, which have strict ordering requirements.

\paragraph{statbench.} In general, it's difficult to argue that an
implementation of a
non-commutative interface achieves the best possible scalability for
that interface and that no implementation could scale better.  However,
in limited cases, we can do exactly this.  We start with statbench,
which measures the scalability of \code{fstat} with respect to
\code{link}.  This benchmark creates a single file that $n/2$ cores
repeatedly \code{fstat}. The other $n/2$ cores repeatedly
\code{link} this file to a new, unique file name, and then \code{unlink}
the new file name.  As discussed in \cref{sec:posix}, \code{fstat} does not
commute with \code{link} or \code{unlink} on the same file because
\code{fstat} returns the link count.  In practice,
applications rarely invoke \code{fstat} to get the link count, so \sys
introduces \code{fstatx}, which allows applications to request specific
fields (a similar system call has been proposed for
Linux~\cite{linux:xstat}).

\XXX[AC]{Mention that commutative statbench helps verify our
disjoint-access parallelism assertion on real hardware.}

\newcounter{mysubfigure}[figure]
\renewcommand{\themysubfigure}{\thefigure(\alph{mysubfigure})}

\begin{figure*}
  % hbox prevents wrapping and fixes nasty vertical space when we
  % overfill
  \hbox{
    % Make subfigure labels refer to correct figure
    \stepcounter{figure}
    \input{graph/linkbench.tex}
    \refstepcounter{mysubfigure}
    \label{fig:linkbench}
    \hspace{-.22in}
    \input{graph/fdbench.tex}
    \refstepcounter{mysubfigure}
    \label{fig:fdbench}
    \hspace{-.22in}
    \input{graph/mailbench.tex}
    \refstepcounter{mysubfigure}
    \label{fig:mailbench}
    \addtocounter{figure}{-1}
  }
  \caption{Benchmark throughput in operations per second per core with
    varying core counts on \sys.
    The blue dots indicate single core Linux
    performance for comparison. \XXX{Split out mailbench.}}
\end{figure*}

% \begin{figure}
%   \centering
%   \input{graph/linkbench.tex}
%   \caption{\code{fstat} throughput with $n/2$ cores running \code{fstat}
%     and $n/2$ cores running \code{link}/\code{unlink}.}
%   \label{fig:linkbench}
% \end{figure}

We run statbench in two modes: one mode uses \code{fstat}, which does
not commute with the \code{link} and \code{unlink} operations performed
by the other threads, and the other mode uses \code{fstatx} to request
all fields except the link count, an operation that \emph{does} commute
with \code{link} and \code{unlink}.  We use a \refcache scalable
counter for the link count so that the
\code{link}s and \code{unlink}s are conflict-free, and place it on
its own cache line to avoid false sharing.
\Cref{fig:linkbench} shows the results.  With the commutative
\code{fstatx}, statbench scales perfectly and experiences zero L2 cache
misses in \code{fstatx}, while the traditional \code{fstat} severely
limits the
scalability of statbench.  

%This is no implementation fluke. 
To better
isolate the difference between \code{fstat} and \code{fstatx}, we run
statbench in a
third mode that uses \code{fstat}, but represents the link count
using a simple shared counter instead of \refcache.  In this mode, \code{fstat}
performs better (at the expense of \code{link} and \code{unlink}), but
still does not scale.  With a shared link count, each \code{fstat}
call experiences exactly one L2 cache miss (for the cache line
containing the link count), which means this is the most scalable that
\code{fstat} can possibly be in the presence of concurrent \code{link}s
and \code{unlink}s.  Yet, despite sharing only a single cache line, the
seemingly innocuous conflict arising from the non-commutative
interface limits the
implementation's scalability.  One small tweak to make the operation
commute by omitting \code{st_nlink} eliminates the barrier to scaling,
demonstrating that even an optimal implementation of a non-commutative
operation can have severely limited scalability.

In the case of \code{fstat}, optimizing for scalability sacrifices some
sequential performance.  Tracking the link count with \refcache
(or some scalable counter) is necessary to make \code{link} and
\code{unlink} scale linearly, but requires \code{fstat} to reconcile the
distributed link count to return \code{st_nlink}.  The exact overhead
depends on the core count, which determines the number of \refcache
caches, but with 80 \refcache caches, \code{fstat} is \pyexpr{times(
  mean(linkbench.filter(("iv.st_nlink",True),("iv.stats",1),("iv.FS_NLINK_REFCOUNT","refcache::"))["dv.cycles/stat"]),
  mean(linkbench.filter(("iv.st_nlink",True),("iv.stats",1),("iv.kernel","Linux"))["dv.cycles/stat"]))}
more expensive than on Linux.  \XXX[AC]{Haven't tried optimizing this.}
%
In contrast, \code{fstatx} can avoid this overhead unless the caller
requests link counts; like \code{fstat} with a shared count, it
performs similarly to Linux's \code{fstat} on a single core.
%\pyexpr{int(mean(linkbench.filter(("iv.st_nlink",True),("iv.stats",1),("iv.FS_NLINK_REFCOUNT","::"))["dv.cycles/stat"]))}~cycles
% Above 20~cores, the shared link count and \refcache link count
% implementations of \code{fstat} scale similarly.

\paragraph{openbench.} \Cref{fig:fdbench} shows the results
of openbench, which stresses the file descriptor allocation performed by
\code{open}.  In openbench, $n$ threads concurrently \code{open} and
\code{close} per-thread files.  These calls do not commute because each
\code{open} must allocate the lowest unused file
descriptor in the process.  For many applications, it suffices to return
any unused file descriptor (in which case the \code{open} calls commute),
so \sys adds an \code{O_ANYFD} flag to \code{open}, which it implements
using per-core partitions of the FD space.  Much like
statbench, the standard, non-commutative \code{open} interface limits
openbench's scalability, while openbench with \code{O_ANYFD} scales
linearly.  Furthermore, there appears to be no performance penalty to
\fs's \code{open}, with or without \code{O_ANYFD}: at one core, both
cases perform identically and outperform Linux's \code{open} by
\pyexpr{percent(
  mean(fdbench.filter(("iv.cores",1),("iv.kernel","xv6"),("iv.any_fd",False))["dv.opens/sec"])
  /mean(fdbench.filter(("iv.cores",1),("iv.kernel","Linux"))["dv.opens/sec"])
  -1)}.
Some of the performance difference is because \sys doesn't implement things like
permissions checking, but much of Linux's overhead comes from locking
that \fs avoids.

% \begin{figure}
%   \centering
%   \input{graph/fdbench.tex}
%   \caption{\code{open} throughput with varying FD allocation policies.}
%   \label{fig:fdbench}
% \end{figure}

\begin{comment}
\paragraph{sockbench.}

\Cref{fig:sockbench} shows the results of sockbench, which
stresses local sockets.  In sockbench $n$ client processes repeatedly
send a 1-byte message over a local socket to $n$ server processes and
wait for a 1-byte response. The clients send the 1 byte message over a
datagram socket that is shared among all servers.  The POSIX API doesn't
require that datagram messages be delivered in order but most operating
systems do enforce this ordering because a single queue for a socket is
the most straightforward implementation.  This unnecessary ordering,
however, makes \code{sendto} invocations on a datagram socket needlessly
non-commutative.

\sys allows for out of order delivery of datagram messages, making
invocations to \code{sendto} commute with each other.  \sys takes
advantage of this commutativity to achieve scalability as follows. When
\sys notices that several cores are receiving from a shared datagram
socket, it partitions the socket among the cores.  A sending core puts a
message into its local partition of the socket, unless its partition is
full.  If the partition is full, \sys invokes a scalable load balancing
algorithm to deliver the message into another partition.

As the results in \Cref{fig:sockbench} show, \sys scales
perfectly, because each pair of a client and a server communicate
through its local partition of the datagram socket.  Thus, cores don't
need to share any cache lines, and \sys scales perfectly.  Linux scales
until a small number of cores, and then collapses because of a contended
spin lock protecting the in-kernel queue for the datagram socket.
\sys's scalability doesn't come at the cost of single-core performance;
in fact, \sys's single core performance is better than Linux.

If an application performs its own load balancing, it could implement
\sys's approach at the application level by setting up $n$ datagram
sockets, for each pair of a client and a server.  With this setup
invocations to \code{sendto} commute because they involve different
datagram sockets.  Unfortunately, today this setup does not result in
better scalability on Linux.  The line labeled ``$n$ datagram sockets''
shows better scalability than the line ``1 datagram socket'', but it
also collapses. At 20 cores, a spin lock protecting the name lookup in
\code{sendto} becomes contended.

The application could perform the name lookup once by a setting up a
stream socket at the beginning, and then using \code{send} to
communicate.  This setup results in better scalability (see the line
labeled ``Linux with $n$ streams''). But, in this setup, a spin
lock in the scheduler becomes a bottleneck (\XXX[FK]{double check}).
Clearly, Linux developers could remove these bottlenecks.  What is nice
about our approach is that the commutativity rule makes clear that these
locks can be removed and that \tool{} can catch these non-scalable
invocations that should be scalable.  \XXX[FK]{We should mention
somewhere that we have a model for unordered and ordered sockets.}

\begin{figure}
  \centering
  \input{graph/usocket.tex}
  \caption{Scalability of $n$ clients concurrently sending and receiving 1
    byte messages to/from $n$ server  processes.}
  \label{fig:sockbench}
\end{figure}
\end{comment}

%     lazy unmap [doing more than one thing]
%     thread-level mmap?
%     stat vs. fstat (name lookup)

\subsection{File system application performance}
\label{sec:eval:app}

We perform a similar experiment using a simple mail server to
produce a file system workload more representative of a real
application.  Our mail server uses a sequence of separate, communicating
processes, each with a specific task, roughly like qmail~\cite{qmail}.
{mail-enqueue} takes a mailbox name and a single message on
stdin, writes the message and the envelope to two files in a
mail queue directory, and notifies the queue manager by writing the
envelope file
name to a Unix domain datagram socket.  {mail-qman} is a long-lived
multithreaded process where each thread reads from the notification
socket, reads the envelope information, opens the queued message, spawns
and waits for the delivery process, and then deletes the queued message.
Finally, {mail-deliver} takes a mailbox name and a single message
on stdin and delivers the message to the appropriate Maildir.
The benchmark models a mail client with $n$ threads that continuously
deliver email by spawning and feeding {mail-enqueue}.

As in the microbenchmarks, we run the mail server in two configurations:
in one we use lowest FD, an order-preserving socket for queue
notifications, and \code{fork}/\code{exec} to spawn helper processes; in
the other we use \code{O_ANYFD}, an unordered notification socket, and
\code{posix_spawn}, all as described in \cref{sec:posix}.
%\code{openbench} explored the limitations of lowest
%FD.
For queue notifications, we use a Unix domain datagram socket;
\sys implements this with a single shared queue in ordered mode and with
per-core message queues with scalable load balancing in unordered
mode.  Finally, because \code{fork} commutes with essentially no other
operations in the same process,
\sys implements \code{posix_spawn} by constructing the new process image
directly and building the new file
table. This implementation is conflict-free with most other operations,
including operations on
\code{O_CLOEXEC} files (except those specifically \code{dup}ed into the
new process).

\Cref{fig:mailbench} shows the resulting scalability of these two
configurations.  Even though the mail server performs a much broader mix
of operations than the microbenchmarks and doesn't focus solely on
non-commutative operations, the results are quite similar.
Non-commutative operations cause the benchmark's throughput to collapse
at a small number of cores, while the configuration that uses
commutative APIs achieves \pyexpr{times(
  mean(mailbench.filter(("iv.cores",80),("iv.alt","all"),("iv.kernel","xv6"))["dv.messages/sec"]),
  mean(mailbench.filter(("iv.cores",10),("iv.alt","all"),("iv.kernel","xv6"))["dv.messages/sec"]))}
scalability from 1~socket
(10~cores) to 8~sockets.
%
% In the non-commutative case, mailbench on \sys slightly outperforms
% Linux.
%
\XXX[AC]{We could also make the point that, the commutative APIs
outperform the non-commutative APIs on one core, in addition to
out-scaling them.}

\XXX[AC]{In the commutative case, our scalability is currently limited
by the growing chains in the fixed-size dcache hash table of the
Maildir.  A resizable hash table would probably help.}

\XXX[AC]{In the non-commutative case, the top problem is fork by far.
However, with \code{posix_spawn} instead of fork, we spend all of our
time in \code{posix_spawn}, which scales but is slow.  If its
\emph{sequential} performance were better, the other things mailbench
does would matter more.}

% \begin{figure}
%   \centering
%   \input{graph/mailbench.tex}
%   \caption{Throughput of $n$ mail agents sending messages to a mail
%     server, which delivers them to a Maildir.}
%   \label{fig:mailbench}
% \end{figure}

\begin{comment}
\begin{figure}
  \centering
  \input{graph/forktest.tex}
  \caption{Scalability of $n$ cores forking and exiting a process on xv6
    and Linux.}
  \label{fig:forktest}
\end{figure}
\end{comment}


\subsection{Virtual memory microbenchmarks}

To understand the scalability and performance of \sys's \vm virtual
memory system, we use three microbenchmarks, each of which exercises a
specific pattern of address space usage.

\Cref{fig:vm-tput} shows the throughput of our three microbenchmarks
on \sys, Bonsai, and Linux.
%
For consistency, we measure the number of pages written per second per
core in all three benchmarks.
%
In \sys, because of per-core page tables, each of these writes
translates into a page fault, even if the page has already been
allocated by another core.
%
Linux and Bonsai incur fewer page faults than \sys for the pipeline
and global microbenchmarks because every core uses the same page
table.

\begin{figure*}
  \centering
  \hbox{
    \stepcounter{figure}
    \input{graph/vm-local-tput.tex}
    \refstepcounter{mysubfigure}
    \label{fig:vm-tput:local}
    \hspace{-.25in}
    \input{graph/vm-pipeline-tput.tex}
    \refstepcounter{mysubfigure}
    \label{fig:vm-tput:pipeline}
    \hspace{-.25in}
    \input{graph/vm-global-tput.tex}
    \refstepcounter{mysubfigure}
    \label{fig:vm-tput:global}
    \addtocounter{figure}{-1}
  }
  %
  \splitcaption{Virtual memory microbenchmark throughput}{in page
    writes per second per core with varying core counts.}
  \label{fig:vm-tput}
\end{figure*}

\paragraph{vmlocal.} The vmlocal microbenchmark exercises completely
disjoint address space usage.
%
In vmlocal, each thread \code{mmap}s a single page in the shared
address space, writes to the page (invoking \code{pagefault}), and
then \code{munmap}s the page.
%
Because each thread maps a page at a different virtual address, all
operations performed by vmlocal commute.

Many concurrent memory allocators use per-thread memory pools that
specifically optimize for thread-local allocations and exhibit this
pattern of address space manipulation~\cite{jemalloc,tcmalloc}.
However, such memory allocators typically map memory in large batches
and conservatively return memory to the operating system to avoid
burdening on the virtual memory system.
%
Our microbenchmark does the opposite, using 4~KB regions to maximally
stress the VM system.

The vmlocal microbenchmark scales linearly on \sys.
%
While this benchmark does incur cache misses, none are conflict misses
and none require cross-core communication.
%
Regardless of the number of cores, we observe about 75 L2 cache misses
per iteration and about 50 L3 cache misses, almost all a result of
page zeroing.
%
None of these require cross-socket communication as all are satisfied
from the core's local DRAM, which is consistent with \tool's
determination that these operations are conflict-free.
%
Likewise, because \sys can track remote TLBs precisely, the vmlocal
microbenchmark sends no TLB shootdowns.
%
Because these operations are conflict-free---there is no lock
contention, a small and fixed number of cache misses, no remote DRAM
accesses, and no TLB shootdowns---the time required to \code{mmap},
\code{pagefault}, and \code{munmap} is constant regardless of the
number of cores.
%
Linux and Bonsai, on the other hand, slow down as we add more cores.
%
This is not unexpected: Linux acquires the address space lock three
times per iteration and Bonsai twice per iteration, effectively
serializing the benchmark.
% \XXX[AC]{Non-scalable locks are the reason for slow down beyond
% serialization.}
%
\sys also demonstrates good sequential performance: at one core,
\sys's performance is within 8\% of Linux, and it is likely this could
be improved.

\paragraph{vmpipeline.} The vmpipeline benchmark captures the pattern
of streaming or pipeline communication, such as a \emph{map} task
communicating with a \emph{reduce} task in
MapReduce~\cite{dean:mapreduce}.
%
In vmpipeline, each thread \code{mmap}s a page of memory, writes to
the page, and passes the page to the next thread in sequence, which
also writes to the page and then \code{munmap}s it.
%
These operations do not commute and the implementation is not
conflict-free.
%
However, unlike the non-commutative cases in the file system
benchmarks, in vmpipeline, the number of cores conflicting on each
cache line remains constant as we increase the total number of cores.
\XXX[AC]{This introduces a new concept, but it's not really because of
  that new concept.}
%
As a result, vmpipeline still scales well on \sys, but not linearly.
%
We observe similar cache miss rates as vmlocal, but vmpipeline induces
cross-socket memory references for pipeline synchronization, returning
freed pages to their home nodes when they are passed between sockets,
and cross-socket shootdown IPIs.
% 0.07 cache lines moved per iteration
For Linux and Bonsai, vmpipeline is almost identical to vmlocal except
that it writes twice to each page; hence we see almost identical
performance, scaled up by a factor of two.
%
Again, \sys's single core performance is within 8\% of Linux.

% TLB shootdowns/iteration is fixed at 1.2, but cycles/TLB shootdown
% grows from ~7000 at 10 cores to 37000 at 80 cores (not enough to add
% up to the cycles/iteration growth).  cycles/munmap tracks this.
% cycles/mmap is relatively constant.  cycles/alloc page fault also
% grows from ~6000 at 10 cores to ~12000 at 80 cores.

\paragraph{vmglobal.} Finally, vmglobal simulates a widely shared
region such as a memory-mapped library or a shared data structure like
a hash table.
%
In vmglobal, each thread \code{mmap}s a 64~KB part of a large region
of memory, then all threads access all of the pages in the large
region in a random order.
%
These operations commute within each phase, but not between phases.

Vmglobal also scales well on \sys, despite being conceptually poorly
suited to \sys's per-core page tables and targeted TLB shootdown.  In
this benchmark, \sys performance is limited by the cost of TLB
shootdowns: at 80 cores, delivering shootdown IPIs to the other 79
cores and waiting for acknowledgments takes nearly a millisecond.
% 1.8 million cycles
However, at 80~cores, the shared region is 20~MB, so this cost is
amortized over a large number of page faults.
%
Linux and Bonsai perform better on this benchmark than on vmlocal and
vmpipeline because it has a higher ratio of page faults to \code{mmap}
and \code{munmap} calls, but they still fail to scale.


\subsection{Virtual memory application benchmark}

To evaluate the impact of \vm on application performance, we use
Metis, a high-performance single-server multithreaded MapReduce
library, to compute a word position index from a 4~GB in-memory text
file~\cite{dean:mapreduce,metis:tr}.
%
Metis exhibits all of the sharing patterns exercised by the
microbenchmarks: it uses core-local memory, it uses a globally shared
B+-tree to store key-value pairs, and it also has pairwise sharing of
intermediate results between \emph{map} tasks and \emph{reduce} tasks.
%
Metis also allows a direct comparison with the Bonsai virtual memory
system~\cite{clements:bonsai}, which used Metis as its main benchmark.

By default Metis uses the Streamflow memory
allocator~\cite{schneider:streamflow}, which is designed to minimize
pressure on the VM system, but nonetheless suffers from contention in
the VM system when running on Linux~\cite{clements:bonsai}.  Previous
systems that used this library avoided contention for in-kernel locks
by using super pages and improving the granularity of the super page
allocation lock in Linux~\cite{boyd-wickizer:scaling}, or by having
the memory allocator pre-allocate all memory upfront~\cite{metis:tr}.
While these workarounds do allow Metis to scale on Linux, we wanted to
focus on the root scalability problem in the VM system rather than the
efficacy of workarounds and to eliminate compounding factors from
differing library implementations, so we use a custom allocator on
both Linux and \sys designed specifically for Metis.  In contrast with
general-purpose memory allocators, this allocator is simple and
designed to have no internal contention: memory is mapped in
fixed-sized blocks, free lists are exclusively per-core, and the
allocator never returns memory to the OS.

Two factors determine the scalability of Metis: conflicts between
concurrent \code{mmap}s during the \emph{map} phase and conflicts
between concurrent \code{pagefault}s during the \emph{reduce} phase.
%
If the memory allocator uses a large allocation unit, Metis
can avoid the first source of contention by minimizing the number of
\code{mmap} invocations.
%
Therefore, we measure Metis using two different allocation units: 8~MB
to stress \code{pagefault} and 64~KB to stress \code{mmap}.
%
At 80 cores, Metis invokes \code{mmap} 5,987 times in the 8~MB
configuration, and 572,292 in the 64~KB configuration.
%
In both cases, it invokes \code{pagefault} approximately 12~million
times, where 70\% of these page faults cause it to allocate new
physical pages and the rest bring pages already faulted on another
core in to the per-core page tables.

\begin{figure}
  \centering
  \input{graph/wrmem.tex}
  %
  \splitcaption{Metis application scalability}{for different VM
    systems and allocation block sizes.}
  \label{fig:metis}
\end{figure}

\XXX![AC]{Text below here needs some work.}
\XXX![AC]{Re-run Metis on \sys.  Something went wonky.  Maybe figure
  out why it doesn't scale perfectly with 64~KB regions?}

\Cref{fig:metis} shows how Metis scales for the inverse indexing
application for the three VM systems.  Metis on \sys scales well with
both large and small allocation sizes, substantially out-performing
and out-scaling Linux in both configurations, and out-performing
Bonsai in the 64~KB \code{mmap}-heavy configuration.  For the 8~MB
\code{pagefault}-heavy configuration, both \sys and Bonsai scale
near-linearly, since both have conflict-free \code{pagefault}
implementations.
%
\sys is $\sim5\%$ slower than Bonsai at all core counts, suggesting
that there is little or no performance penalty to \vm's very different
design; it's likely we could close this gap with further work on the
sequential performance of \sys.
%
Unlike Bonsai, \sys achieves highly scalable \code{mmap} and
\code{munmap}, in addition to scalable \code{pagefaults}.

On Linux, both concurrent \code{mmap}s and concurrent
\code{pagefault}s contend for the address space lock and, as a result,
Metis on Linux scales poorly with both small and large allocation
units.
%
For small allocation units, the workload is largely serialized by
\code{mmap}s.
%
For large allocations, the workload is dominated by \code{pagefault}s;
these process in parallel, but on after incurring cache line conflicts
to acquire the address space lock in shared mode.
\XXX[AC]{I think the previous sentence could be more direct.}

% LocalWords:  microbenchmark microbenchmarks vmlocal vmpipeline vmglobal
