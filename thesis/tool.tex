\section{Analyzing interfaces using \tool}
\label{sec:tool}

\XXX[STATUS]{\analyzer section rewritten from SOSP.  Planning to
  expand \testgen section a bit.}

Fully understanding the commutativity of a complex interface is
tricky, and achieving an
implementation that avoids sharing when operations commute adds another
dimension to an already difficult task.  However, by leveraging the
formality of the commutativity rule, developers can automate much of this
reasoning.  \Thiscref{sec:tool} presents a systematic, test-driven approach to
applying the commutativity rule to real implementations embodied in a
tool named \tool, whose components are shown in
\cref{fig:tool}.


\begin{figure*}
\input{figures/tool.tex}
\caption{The components of \tool.}
\label{fig:tool}
\end{figure*}

First, \analyzer takes a symbolic model of
an interface and computes precise conditions under which that interface's
operations commute.  Second, \testgen takes
these conditions and generates concrete test cases of sets of operations
that commute according to the interface model, and thus should
have a conflict-free implementation according to the commutativity rule.
%
Third, \mtrace checks whether a particular implementation is
conflict-free for each test case.

A developer can use these test cases to understand the
commutative cases they should consider,
to iteratively find and fix scalability
issues in their
code, or as a regression test suite to ensure
scalability bugs do not creep into the implementation over time.


\subsection{\analyzer}
\label{sec:tool:analyzer}

% Alternate outline: Step through in detail with two operations,
% following commutes2 algorithm, then generalize to sets of operations
% in the obvious way, then discuss $n$-cube optimization.  Need to
% cover 1) how to get from the path conditions to the commutativity
% condition, 2) how \code{commutes} differs from SIM commutativity,
% and 3) how we implement ``internal'' variables.  Also need to
% explain (preferably early) how this connects to SIM commutativity:
% that the unconstrained initial state represents all possible
% histories that could come before the operations under test and that
% testing for final state equivalence tests whether any future $Z$ can
% distinguish the different orders.  This keeps things grounded in
% examples from the start, but front-loads symbolic execution and
% separates the rename example from the transition into testgen.


\analyzer automates the process of analyzing the commutativity of an
interface, saving developers from the tedious and error-prone process of
considering large numbers of interactions between complex operations.
%
\analyzer takes as input a model of the behavior of an interface,
written in a symbolic variant of Python, and outputs \emph{commutativity
  conditions}: expressions in terms of arguments and state for exactly
when sets of operations commute.
%
A developer can inspect these expressions to understand an interface's
commutativity or pass them to \testgen (\cref{sec:tool:generator})
to generate concrete examples of when interfaces commute.

% Diagrammatically, something like:
%                        /- op_b=>r_ab @ S_ab -- op_c=>r_abc @ S_abc
%       / op_a=>r_a @ S_a
%      /                 \- op_c=>r_ac @ S_ac -- op_b=>r_acb @ S_acb
%     /                  /- op_a=>r_ba @ S_ba -- op_c=>r_bac @ S_bac
% S_0 --- op_b=>r_b @ S_b
%     \                  \- op_c=>r_bc @ S_bc -- op_a=>r_bca @ S_bca
%      \                 /- op_a=>r_ba @ S_ca -- op_b=>r_cab @ S_cab
%       \ op_c=>r_c @ S_c
%                        \- op_b=>r_bc @ S_cb -- op_a=>r_cba @ S_cba
%
%   (r_a == r_ba == r_bca == r_ca == r_cba) /\
%   (r_b == r_ab == r_acb == r_cab == r_cb) /\
%   (r_c == r_abc == r_ac == r_bac == r_bc) /\
%   (S_ab == S_ba) /\ (S_ac == S_ca) /\ (S_bc == S_cb) /\
%   (S_abc == S_acb == S_bac == S_bca == S_cab == S_cba)
%
% See also [[2013-08-21 :SCP Analyzer pseudo-code]]
%
% Actually, many of these comparisons are redundant.  See the whiteboard
% photo from 2013-09-14.

Given the Python code for a model, \analyzer uses symbolic execution to
consider all possible behaviors of the interface model and construct
complete commutativity conditions.  Symbolic execution also enables
\analyzer to reason about the external behavior of an interface, rather
than specifics of the model's implementation, and enables models to
capture specification non-determinism (like \code{creat}'s ability to
choose any free inode) as under-constrained symbolic values.

% Larger sets are exponentially more expensive: An n-cube has n *
% 2^(n-1) edges, so each individual commutativity test is exponential
% in the number of operations (symbolic branching probably makes this
% doubly exponential, and the growing path condition at least adds a
% polynomial factor and may add another exponential).  The number of
% tests we need to do is nCr(n + k - 1, k) where n is the number of
% interface operations and k is the number under test.  This probably
% makes it triply exponential, but I'm not sure what the growth in k
% is.

\subsubsection{Concrete commutativity analysis}

Starting from such a model, \analyzer computes the commutativity
condition of each multiset of operations of a user-specified size.
%
To determine whether a set of operations commutes, \analyzer executes
the SIM commutativity test algorithm given in \cref{fig:commutes}.  To
begin with, we can think of this test in concrete (non-symbolic) terms
as a test of whether a set of operations commutes starting from a
specific initial state \code{s0} and given specific operation
arguments \code{args}.

\begin{figure}
  \inputcode{code/commutes}
  %
  \splitcaption{The \SIM commutativity test algorithm.}{\code{s0} is
    the initial state, \code{ops} is the list of operations to test
    for commutativity, and \code{args} gives the arguments to pass to
    each operation.  For clarity, this implementation assumes all
    values in ops are distinct.}
  \label{fig:commutes}
\end{figure}

% Alternate code:
% def commutes(s0, ops, args):
%   results, states = {}, {}
%   for perm in permutations(ops):
%     s = s0.copy()
%     for i, op in enumerate(perm):
%       r = op(s, args[op])
%
%       # Test result equivalence
%       if op not in results:
%         results[op] = r
%       elif r != results[op]:
%         return False
%
%       # Test state equivalence
%       op_set = frozenset(perm[:i+1])
%       if op_set not in states:
%         states[op_set] = s.copy()
%       elif s != states[op_set]:
%         return False
%  return True

\code{commutes} codifies the definition of \SIM commutativity, except
that it requires the specification to be sequentially consistent so it
needn't interleave partial operations.  Recall that $\HY$ \SI-commutes
in $H = \HX \HCONCAT \HY$ when, given any reordering $\HY'$ of $\HY$
and any action sequence $\HSUFF$, \[\HX \HCONCAT \HY \HCONCAT \HSUFF
\in \SPEC \text{~~~if and only if~~~} \HX \HCONCAT \HY' \HCONCAT
\HSUFF \in \SPEC.\]  Further, for $\HY$ to \SIM-commute in $H$, every
prefix of every reodering of $\HY$ must \SI-commute.
%
In \code{commutes}, the initial state \code{s0} serves the role of the
prefix $\HX$: to put the system in some state.
% For alternate code:
% The outer loop of \code{commutes} considers all reorderings ($\HY'$)
% of the operations under test (assuming sequential consistency).  The
% inner loop executes each individual reordering and performs a result
% test and a state test.
\code{ops} serves the role of $\HY$ (assuming sequential consistency)
and the loop in \code{commutes} generates every $\HY'$, that is, all
prefixes of all reoderings of $\HY$.  This loop performs two tests.
First, the result equivalence test ensures that each operation gives
the same response in all reorderings.  Finally, the state equivalence
test serves the role of the future actions, $\HSUFF$, by requiring all
prefixes of all reorderings to converge on states that are
indistinguishable by future operations.

Since \code{commutes} substitutes state equivalence in place of
considering all possible future operations (which would be difficult
with symbolic execution), it's up to the model's author to define
state equivalence as whether two states are externally
indistinguishable.  This is standard practice for high-level data
types (e.g., two sets represented as trees could be equal even if they
are balanced differently).  For the POSIX model we present in
\cref{sec:model}, only a few types need special handling beyond what
\analyzer's high-level data types already provide.

The \code{commutes} algorithm can be optimized by observing that if
two permutations of the same prefix reach the same state, only one
needs to be considered further.  This optimization gives
\code{commutes} a pleasing symmetry: it becomes equivalent to
exploring all $n$ step paths from $\tup<0,0,\ldots>$ to
$\tup<1,1,\ldots>$ in an $n$-cube, where each unit step is an
operation and each vertex is a state.


\subsubsection{Symbolic commutativity analysis}
\label{sec:topic:rename-conditions}

So far, we've considered only how to determine if a set of operations
commutes for a specific initial state and specific arguments.
Ultimately, we're interested in the entire space of states and
arguments for which a set of operations commutes.  To find this,
\analyzer executes \code{commutes} \emph{symbolically}, passing it an
unconstrained symbolic initial state and unconstrained symbolic
operation arguments.  Symbolic execution lets \analyzer efficiently
consider \emph{all possible} initial states and arguments and
precisely determine the (likely infinite) set of states and arguments
for which the operations commute (that is, for which \code{commutes}
returns \code{True}).

\begin{figure}
  \inputcode{code/rename}
  \caption{A simplified version of our \code{rename} model.}
  \label{fig:rename-spec}
\end{figure}

\Cref{fig:rename-spec} gives an example of how a developer could model
the \code{rename} operation in \analyzer.  The first five lines
declare symbolic types used by the model (\code{tuninterpreted}
declares a type whose values support only equality).  The \code{POSIX}
class, itself a symbolic type, represents the \emph{system state} of
the file system and its methods implement the interface operations to
be tested.  The implementation of \code{rename} itself is
straightforward.  Indeed, the familiarity of Python and ease of
manipulating state were part of why we chose it over abstract
specification languages.

% \begin{figure}
%   \inputcode{code/commutes2-old}
%   \splitcaption{The \SIM commutativity test algorithm for two
%     operations.}{\tool executes \code{commutes} symbolically and
%     \code{commutes} executes the operations being tested.  Given a
%     system state type and two operations, \code{commutes} returns
%     whether the operations commute under the constraints of the path
%     condition that leads to the return.}
%   \label{fig:commutes2-old}
% \end{figure}
\begin{figure}
  \inputcode{code/commutes2}
  \caption{The \SIM commutativity test algorithm specialized to two
    operations.}
  \label{fig:commutes2}
\end{figure}

To explore how \analyzer analyzes \code{rename}, we'll use the version
of \code{commutes} given in \cref{fig:commutes2}, which is specialized
for pairs of operations.  In practice, we typically analyze pairs of
operations rather than larger sets because larger sets take
exponentially longer to analyze and rarely reveal problems beyond
those already revealed by pairs.

% Derived from figures/tree.tex
\newcommand\treecommutes{%
  \tikz[y=-0.0111111in,x=0.0111111in]{
    \definecolor{tmpfill}{rgb}{0,1,0}
    \path[fill=tmpfill] (0,0) circle (4.29);
    \node[font=\fontsize{5}{6}\selectfont,text=white,inner sep=0pt] {\checkmark};
  }%
}
\newcommand\treediverges[1]{%
  \tikz[y=-0.0111111in,x=0.0111111in]{
    \definecolor{tmpfill}{rgb}{1,0,0}
    \path[fill=tmpfill] (0,0) circle (4.29);
    \node[font=\fontsize{5}{6}\selectfont,text=white,inner sep=0pt] {#1};
  }%
}
\begin{figure}
  \centering
  \inputnodraft{figures/tree.tex}
  %
  \splitcaption{Symbolic execution tree of \code{commutes2} for
    \code{rename/rename}.}{Each node represents a conditional branch
    on a symbolic value.  The terminals at the bottom indicate whether
    each path constraint yields a commutative execution of the two
    operations (\treecommutes), or, if not, whether it diverged on
    return values (\treediverges{R}) or final state
    (\treediverges{S}).}
  \label{fig:rename-branching}
\end{figure}

\XXX[AC]{Add line labels to figure that match up with code listings?}

\XXX[AC]{Show initial path condition and some final path conditions in
  figure?}

\Cref{fig:rename-branching} illustrates the symbolic execution of
\code{commutes2} testing a pair of \code{rename} operations.
%
By and large, this symbolic execution proceeds like regular Python
execution, except when it encounters a conditional branch on a
symbolic value (such as any \code{if} statement in \code{rename}).
Symbolic execution always begins with an empty symbolic \emph{path
  condition}.  To execute a conditional branch on a symbolic value,
\analyzer uses an SMT solver to determine whether that symbolic value
can be true, false, or either, given the path condition accumulated so
far.
%
If the branch can go both ways, \analyzer logically forks the symbolic
execution and extends the path conditions of the two forks with the
constraints that the symbolic value must be true or false,
respectively.  These growing path conditions thereby constrain further
execution on the two resulting code paths.

The four main regions of \cref{fig:rename-branching} correspond to the
four calls to \code{rename} from \code{commutes2} as it tests the two
different reorderings of the two operations.  Each call region shows
the three conditional branches in \code{rename}.  The first call forks
at every conditional branch because the state and arguments are
completely unconstrained at this point; \analyzer therefore explores
every code path through \code{rename}.  The second call forks
similarly.  The third and fourth calls generally do not fork; by this
point, the symbolic values of \code{s0}, \code{argsA}, and
\code{argsB} are heavily constrained by the path condition produced by
the first two calls.  As a result, these calls are often forced to
make the same branch as the corresponding earlier call.

Finally, after executing both reorderings of \code{rename/rename},
\code{commutes2} tests their commutativity by checking if each
operation's return value is equivalent in both permutations and if the
system states reached by both permutations are equivalent.  This, too,
is symbolic and may fork execution if it's still possible for the pair
of operations to be either commutative or non-commutative (we see a
couple such forks in \cref{fig:rename-branching}).

Together, the set of path conditions that pass this final
commutativity test are the commutativity condition of this pair of
operations.  Barring SMT solver time-outs, the disjunction of the path
conditions for which \code{commutes2} returns \code{True} captures the
precise set of initial system states and operation arguments for which
the operations commute.

\XXX!{Fix up flow here.}

Given two
\code{rename} operations, \code{rename(a, b)} and \code{rename(c, d)},
\analyzer outputs that they commute if any of the following hold:

\begin{CompactItemize}
\item Both source files exist, and the file names are all different
      (\code{a} and \code{c} exist, and \code{a}, \code{b}, \code{c},
      \code{d} all differ).

\item One \code{rename}'s source does not exist, and it is not the
      other \code{rename}'s destination (either
      \code{a} exists, \code{c} does not, and \code{b}$\neq$\code{c}, or
      \code{c} exists, \code{a} does not, and \code{d}$\neq$\code{a}).

\item Neither \code{a} nor \code{c} exist.

\item Both calls are self-renames (\code{a}$=$\code{b} and \code{c}$=$\code{d}).

\item One call is a self-rename of an existing file
      (\code{a} exists and \code{a}$=$\code{b}, or
       \code{c} exists and \code{c}$=$\code{d}) and
      it's not the other call's source (\code{a}$\neq$\code{c}).

\item Two hard links to the same inode are renamed to the same new name
      (\code{a} and \code{c} point to the same inode,
       \code{a}$\neq$\code{c}, and \code{b}$=$\code{d}).

\end{CompactItemize}

As this example shows, when system calls access shared, mutable
state, reasoning about every commutative case by hand can become
difficult.
%
Developers can easily overlook cases, both in their
understanding of an interface's commutativity, and when making their
implementation scale for commutative cases.
%
\analyzer
automates reasoning about all possible system states, all possible
sets of operations that can be
invoked, and all possible arguments to those operations.

\XXX[AC]{Are these examples that enlightening?  Do they just reinforce
the ``corner case'' mentality?

For
example, creating two files in two different directories might appear to
be obviously commutative, but in fact if the file system has exactly one
free inode left, these two operations do not commute.
%
As another example, the \code{open()} and \code{stat()} system calls
generally commute if they refer to different file names, but there are a
number of non-obvious cases: e.g., the two operations do not commute if one
of the files does not exist, the other is a symlink to the first, and
\code{open} is invoked with \code{O_CREAT}; or if one file exists and is
non-empty, the other is a symlink to the first, and \code{open} is invoked
with \code{O_TRUNC}.}


\subsection{\testgen}
\label{sec:tool:generator}

While a developer can examine the commutativity conditions
produced by \analyzer directly, for complex interfaces these formulas
can be large and difficult to decipher.  Further, real implementations
are complex and likely to contain unintentional sharing, even if the
developer understands an interface's commutativity.  \testgen takes
the first step to helping developers apply commutativity to real
implementations by converting \analyzer's commutativity conditions into
concrete test cases.

To produce a test case, \testgen computes
a satisfying assignment for the corresponding commutativity condition.
The assignment specifies concrete values for every symbolic variable in
the model, such as the \code{fname_to_inum} and \code{inodes} data structures
and the \code{rename} arguments shown in \cref{fig:rename-spec}.
\testgen then invokes a model-specific function on the assignment
to produce actual C test case code.  For example, one test
case that \testgen generates is shown in \cref{fig:testgen}.
The test case includes setup code that configures the initial state of
the system and a set of functions to run on different cores. Every
\testgen test case should have a conflict-free implementation.

\begin{figure}
\inputcode{code/testgen}
\caption{An example test case for two \code{rename} calls generated by
         \testgen for the model in \cref{fig:rename-spec}.}
\label{fig:testgen}
\end{figure}

The goal of these test cases is to expose potential scalability problems
in an implementation, but it is impossible for \testgen to know
exactly what inputs might trigger conflicting memory accesses.  Thus, as a
proxy for achieving good coverage on the implementation, \testgen
aims to achieve good coverage of the Python model.

\XXX[E]{THIS PARAGRAPH IS VERY OPAQUE}
We consider two forms of coverage.
The first is the standard notion of path coverage, which \testgen
achieves by relying on \analyzer's symbolic execution.
%
\analyzer produces a separate path condition for every possible code
path through a set of operations.
%
However, even a single path might encounter conflicts in interestingly
different ways.
%
For example, the code path through two \code{pwrite}s is the
same whether they're writing to the same offset or different offsets,
but the access patterns are very different.
%
To capture different conflict conditions as well as path conditions, we
introduce a new notion called \emph{conflict coverage}.  Conflict coverage
exercises all possible access patterns on shared data structures:
looking up two distinct items from different operations, looking up
the same item, etc.
%
\testgen approximates
conflict coverage by concolically executing \emph{itself}
to enumerate distinct tests for each path condition.  \testgen
starts with the constraints of a path condition from \analyzer, tracks
every symbolic expression forced to a concrete value by the
model-specific test code
generator, negates any equivalent assignment of these expressions from
the path condition, and generates another test, repeating this process
until it exhausts assignments that satisfy the path condition or the SMT
solver fails.  Since
path conditions can have infinitely many satisfying assignments (e.g.,
there are infinitely many calls to \code{read} with different FD numbers
that return \code{EBADF}), \testgen partitions most values in
\emph{isomorphism groups} and considers two assignments equivalent if
each group has the same
pattern of equal and distinct values in both assignments.  For our POSIX
model, this
bounds the number of enumerated test cases.

These two forms of coverage ensure that the test cases
generated by \testgen will cover all possible paths and data structure
access patterns in the model, and to the extent that the implementation
is structured similarly to the model, should achieve good coverage
for the implementation as well.  As we demonstrate in \cref{sec:model},
\testgen produces a total of \pyexpr{mscan.ntestcases} test cases
for our model of \pyexpr{len(mscan.calls)} POSIX
system calls, and these
test cases find scalability issues in the Linux \code{ramfs} file system
and virtual memory system.


\subsection{\mtrace}
\label{sec:tool:mtrace}

Finally, \mtrace runs the test cases generated by \testgen on
a real implementation and checks that the implementation is
conflict-free for every test.  If it finds a violation of the
commutativity rule---a test whose commutative operations are not
conflict-free---it reports which variables were shared and what code
accessed them.
%
For example, when running the
test case shown in \cref{fig:testgen} on a Linux \code{ramfs}
file system, \mtrace reports that the two functions make conflicting
accesses to the \code{dcache} reference count and lock, which limits
the scalability of those operations.

\mtrace runs the entire operating system in a modified version of
qemu~\cite{qemu}.  At the beginning of each test case, it issues a hypercall to
qemu to start recording memory accesses, and then executes the test
operations on different virtual cores.  During test execution,
\mtrace logs all reads and writes by each core, along with
information about the currently executing kernel thread,
to filter out irrelevant conflicts by background threads or
interrupts.  After execution, \mtrace analyzes
the log and reports all conflicting memory accesses, along with the C
data type of the accessed memory location (resolved from
DWARF~\cite{dwarf} information and logs
of every dynamic allocation's type) and stack traces for each conflicting
access.

\subsection{Implementation}
\label{sec:tool:impl}

We built a prototype implementation of \tool's three components.
\analyzer and \testgen consist of
\pyexpr{const['commuter-loc']['analyzer']} lines of Python code,
including the symbolic execution engine, which uses the Z3 SMT
solver~\cite{demoura:z3}
via Z3's Python bindings.
\mtrace consists of \pyexpr{const['mtrace-loc']['qemu-diff']} lines of
code changed in qemu, along with \pyexpr{const['pk-loc']['pk-diff']}
lines of code changed in the guest
Linux kernel (to report memory type information, context switches, etc.).
Another program, consisting of \pyexpr{const['mtrace-loc']['mscan']}
lines of C++ code, processes the
log file to find and report memory locations that are shared between different
cores for each test case.

\XXX[AC]{mtrace's custom DWARF library dwarfs the rest of this at
$\sim$6,500 LOC.}

% \mtrace is implemented on a modified qemu~\cite{qemu}.  We added support
% for hypercalls so that software running within \mtrace can communicate
% events such as variable declarations, call stack switches, and the range
% and type of every memory allocation.  \mtrace also modifies the qemu
% code generator to intercept all loads and stores and to trace additional
% instructions such as \code{call} and \code{ret} to produce call stacks.
% This information is written to a log file.

