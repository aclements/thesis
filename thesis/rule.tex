\section{The scalable commutativity rule}
\label{sec:rule}

\XXX[STATUS]{
  v3: Applied Eddie init-317-gdbaaa0d.
  v2: Applied Eddie init-244-ga695479.
  v1: Expanded and reworked to focus on conflict-freedom vs SOSP.
%  Planning to add non-commutative non-scalability rule and discussion
%  of global clocks.
}

\Thiscref{sec:rule} addresses two questions: What is the precise
definition of the scalable commutativity rule, and why is the rule
true?
%
We answer these questions using a formalism based on abstract actions,
histories,
and implementations, combined with the empirical result of the
previous \lcnamecref{sec:scalability}.
%
This formalism relies on a novel form of commutativity, \emph{\SIM
  commutativity}, whose generality makes it possible to broadly apply
the scalable
commutativity rule to complex software interfaces.
%
Our constructive proof of the scalable commutativity rule
also sheds some light on how real conflict-free implementations might be
built, though the actual construction is not very practical.


\subsection{Actions}

Following earlier work~\cite{herlihy:linearizability}, 
we model a system execution
as a sequence of \emph{actions}, where an action is either an
\emph{invocation} or a \emph{response}.
%
In the context of an operating system, an invocation represents a system
call with arguments (such as \code{getpid()} or \code{open("file", O_RDWR)}) and a
response represents the corresponding return value (a PID or a file
descriptor).
%
Invocations and responses are paired. Each invocation is made by a
specific thread, and the corresponding response is returned to the same
thread.
%
An action thus comprises (1) an operation class (e.g., which system
call is being invoked); (2) operation arguments (for invocations) or
a return value (for responses); (3) the relevant thread;
and (4) a tag for uniqueness.
%
We'll write invocations as left half-circles \scpline{\scpi{A}{0}}
(``invoke A'') and responses as right half-circles
\scpline{\scpr{A}{0}} (``respond A''), where the letters match
invocations and their responses.
%
Color and vertical offset differentiate threads:
\scpline{\scpi{A}{1}} and \scpline{\scpi{B}{2}} are invocations on
different threads.

\def\historyexample{%
\scpi{A}{1}
\scpi{B}{3}
\scpi{C}{2}
\scpr{A}{1}
\scpr{C}{2}
\scpr{B}{3}
\scpi{D}{1}
\scpr{D}{1}
\scpi{E}{3}
\scpr{E}{3}
\scpi{F}{2}
\scpi{G}{3}
\scpi{H}{1}
\scpr{F}{2}
\scpr{H}{1}
\scpr{G}{3}}

A system execution is called a \emph{history}. For example
%
\[H = \text{\scpline{\historyexample}}\]
%
consists of eight invocations and eight corresponding responses across
three different threads.
%
We'll consider only \emph{well-formed} histories, in which
each thread's actions form a sequence of invocation--response pairs.
$H$ above is well-formed; checking this for the red thread $\scpt{$t$}{1}$, we
see that the thread-restricted subhistory $\HRESTRICT{H}{\scpt{$t$}{1}} =
\text{\scplinerestrictb{1}{\historyexample}}$ formed
by selecting \(\scpt{$t$}{1}\)'s actions from $H$ alternates invocations
and responses as one would want.
%
%\[\HRESTRICT{H}{\scpt{$t$}{1}} = \text{\scplinerestrict{1}{\historyexample}}\]
%\[\HRESTRICT{H}{\scpt{$t$}{x1}} = \text{\scplinerestrictb{1}{\historyexample}}\]
%
%\noindent%
In a well-formed history, each thread has at
most one outstanding invocation at every point.

The \emph{specification} distinguishes whether or not a history is
``correct.''
%
A specification $\SPEC$ is a prefix-closed set of well-formed histories.
%
The set's contents depend on the system being modeled; for example, if $\SPEC$
specified a Unix-like OS, then
$[\scpline{\scpi{A}{0}}=\code{getpid()},
\scpline{\scpr{A}{0}}=0] \not\in \SPEC$, since no Unix thread can
have PID 0.
%
Our definitions and proof require that some specification exists, but we
aren't concerned with how it is constructed.


\subsection{\SIM commutativity}
\label{sec:rule:sim-commutativity}
\label{sec:topic:strong-commutativity}

Commutativity captures the idea that the order of a set
of actions ``doesn't matter.''
%
This happens when the caller of an interface cannot distinguish the
order in which events actually occurred, either through those actions'
responses or through any possible future actions.
%
To formalize this inability to distinguish orders, we use the
specification.
%
A set of actions commutes in some context when the specification
is indifferent to the execution order of that set.
%
This means that any response valid for one order of the commutative set
is valid for {any} order of the commutative set, and likewise any
response invalid for one order is invalid for any order.
%
The rest of this \lcnamecref{sec:rule:sim-commutativity} formalizes
this intuition as \emph{\SIM commutativity}.

Our definition has two goals: state dependence and interface basis.

\emph{State dependence} means \SIM commutativity must to capture when
operations commute in some states, even if those same operations do
not commute in other states.
%
This is important because it allows the rule to apply to a much
broader range of
situations than traditional non-state-dependent notions of
commutativity.
%
For example, few OS system calls unconditionally commute in
every state, but many system calls commute in restricted states.
%
Consider POSIX's \code{open} call.
%
In general, two calls to \code{open("a", O_CREAT|O_EXCL)} don't
commute: one call will create the file and the other will
fail because the file already exists.
%
However, two such calls do commute if called from processes with
different working directories; or if the file \code{"a"} already
exists (both calls will return the same error).
% However, two calls to \code{open("a", O_CREAT|O_EXCL)} \emph{do}
% commute if called from processes with different working
% directories.  And even if the processes have the same working
% directory, two calls to \code{open("a", O_CREAT|O_EXCL)} will commute
% {if the file already exists} (both
% calls will return the same error).
%
\XXX[EK]{Let's expand the example into a history in an itemize or
  something, and show the actual example, with comments such as ``//
  spec requires this open() call return -1''}  \XXX[AC]{I don't really
  know what this means.}
%
State dependence makes it possible to distinguish these cases, even
though the
operations are the same in each.  This, in turn, means the scalable
commutativity
rule can tell us that scalable implementations exist in all of these
commutative
cases.
%
\XXX[AC]{Use rename example from later?  ``For example, the
  \emph{only} case where two \code{rename} operations commute
  regardless of state is when both are self-renames.''}

\emph{Interface basis} means \SIM commutativity must
evaluate the consequences of execution order using only the
specification, without reference to any particular implementation.
%
Since our goal is to reason about
\emph{possible} implementations, it's necessary to capture the
scalability inherent in the interface
itself.
%
This in turn makes it
possible to use the scalable commutativity rule early in software development,
during interface design and initial implementation.
%
% Furthermore, it doesn't say that every reordering has indistinguishable
% results on a \emph{given} implementation; it requires instead that
% every reordering \emph{is allowed by the specification} to have
% indistinguishable results. This is important because any given
% implementation might
% have unnecessary scalability bottlenecks that show through the
% interface.
% %
% For example, an interface in which \code{open} is allowed to return
% \emph{any} unused file descriptor could still be implemented by
% returning the lowest unused file descriptor, which would expose the
% order of \code{open} calls.  But the interface specification permits
% other implementations
% that don't expose order.

The right definition for commutativity that achieves both of these
goals is a little tricky, so we
build it up in two steps.

\paragraph{Definition.}
An action sequence, or region, $H'$ is a \emph{reordering}
of an action sequence $H$ when $\HRESTRICT{H}{t} = \HRESTRICT{H'}{t}$ for
every thread $t$.
%
This is, regions $H$ and $H'$ contain the same invocations and
responses in the same order for each individual thread, but
may interleave threads differently.
%
If $H =
\text{\scpline{\scpi{A}{1} \scpi{B}{2} \scpr{A}{1} \scpi{C}{1} \scpr{B}{2}
    \scpr{C}{1}}}$, then
%
$\text{\scpline{\scpi{B}{2} \scpr{B}{2} \scpi{A}{1} \scpr{A}{1} \scpi{C}{1}
    \scpr{C}{1}}}$
is a reordering of $H$, but
$\text{\scpline{\scpi{B}{2} \scpi{C}{1} \scpr{B}{2} \scpr{C}{1}
    \scpi{A}{1} \scpr{A}{1}}}$
is not, since it doesn't respect the order of actions in $H$'s red thread.

\paragraph{Definition.}
Consider a history $H = \HX \HCONCAT \HY$ (where $\HCONCAT$ concatenates
action sequences).
%
$\HY$ \emph{\SI-commutes} in $H$ when given any reordering
$\HY'$ of $\HY$, and any action sequence $\HSUFF$,
%
\[ \HX \HCONCAT \HY \HCONCAT \HSUFF \in \SPEC \text{~~~if and only if~~~} \HX \HCONCAT \HY' \HCONCAT \HSUFF \in \SPEC. \]
%
This definition
captures the state dependence and interface basis
we need.  The action sequence $\HX$ puts the system
into the state we wish to consider, without specifying any particular
representation of that state (which would depend on an
implementation).
%
Switching regions $\HY$ and $\HY'$
requires that the exact responses in
$\HY$ remain valid according to the specification even if $\HY$ is
reordered.
%
The presence of region $\HSUFF$ in both histories requires
that reorderings of
actions in region $\HY$ are indistinguishable by future operations.
%
% \XXX[E]{There was something about ``This literal transaltion of our
% informal definition of commutativity'' here, but it's not ``literal,''
% and then I'm not sure we have an informal definition of commutativity?
% Maybe the point was to imply this def actually isn't very hard?...}

Unfortunately, \SI commutativity doesn't suffice for our needs
because it is \emph{non-monotonic}.
%
Given an action sequence $\HX \HCONCAT \HY_1 \HCONCAT \HY_2$, it is possible
for $\HY_1 \HCONCAT \HY_2$ to \SI-commute after region $\HX$ even
though $\HY_1$ without $\HY_2$ does not.
%
For example, consider a
\code{get}/\code{set} interface and the action sequence
%
\[\HY =
  [\underbrace{
    \scpline{\scpi{A}{1}}=\code{set(1)}, \scpline{\scpr{A}{1}},
    \scpline{\scpi{B}{2}}=\code{set(2)}, \scpline{\scpr{B}{2}}}_{\HY_1},
   \underbrace{
     \scpline{\scpi{C}{1}}=\code{set(2)}, \scpline{\scpr{C}{1}}}_{\HY_2}].
\]
%
\(\HY\) \SI-commutes in any history because \code{set} never returns
anything and every reordering sets the underlying value to 2, so
future \code{get} operations cannot distinguish reorderings of $\HY$.
%
However, its prefix $\HY_1$
% %
% \[\HY_1 =
%   [\scpline{\scpi{A}{1}}=\code{set(1)}, \scpline{\scpr{A}{1}},
%    \scpline{\scpi{B}{2}}=\code{set(2)}, \scpline{\scpr{B}{2}}]\]
% %
alone does not \SI-commute because some orders set the value to 1 and some
to 2, so future \code{get} operations can distinguish them.
%
Whether or not $\HY_1$ will
ultimately form part of a commutative region thus depends on \emph{future}
operations!  This is usually incompatible with scalability:
operations in $\HY_1$ must ``plan for the worst'' by remembering their
order, even if they ultimately form part of a \SI-commutative region.

Requiring monotonicity eliminates this problem.

\paragraph{Definition.}
%
An action sequence $\HY$ \emph{\SIM-commutes} in a history $H = \HX \HCONCAT
\HY$ when for any \emph{prefix} $P$ of any reordering of $\HY$ (including
$P = \HY$), $P$ \SI-commutes in $\HX \HCONCAT P$.

Return to the \code{get}/\code{set} example, while the sequence $Y$
given in the example \SI-commutes (in any history), $\HY$ does \emph{not}
\SIM-commute because its prefix $\HY_1$ is not \SI commutative.

Like \SI commutativity, \SIM\ commutativity captures 
state dependence and interface basis.  Unlike \SI commutativity, \SIM
commutativity excludes cases where the commutativity of a region
changes depending on future operations and,
as we show below, suffices to prove the
scalable commutativity rule.


% \XXX[rtm]{if my machine has synchronized clocks, do I need ``SIM
% commutative''? would SI commutative be enough?}
% \XXX[E]{I believe that's right.}


\subsection{Implementations}
\label{sec:rule:implementations}

To reason about the scalability of an implementation of an interface,
we need to model
implementations in enough detail to tell
whether different threads' ``memory accesses'' are conflict-free.
%
We represent an implementation as a step
function: given a state and an invocation, it produces a new state and a
response.
%
We can think of this step function as being invoked by a driver
algorithm (a \emph{scheduler} in operating systems parlance) that
repeatedly picks which thread to take a step on and passes state from
one application of the step
function to the next.
%
Special \CONTINUE\ actions let the step function request that the
driver ``run'' a different thread and let us represent
concurrent overlapping operations and blocking operations.

We begin by defining three sets:

\begin{CompactItemize}
\item $S$ is the set of implementation states.
\item $I$ is the set of valid invocations, including \CONTINUE.
\item $R$ is the set of valid responses, including \CONTINUE.
\end{CompactItemize}

\paragraph{Definition.}
An \emph{implementation} $m$ is a function in $S \times I \mapsto S \times R$.
Given an old state and an invocation, the
implementation produces a new state and a response.
%
The response
must have the same thread as the invocation.
%
A \CONTINUE\ response indicates that a real response for that thread is
not yet ready,
and gives the driver the opportunity to take a step on a different
thread without a real response from the current thread.
\CONTINUE\ invocations give the implementation an opportunity to complete an
outstanding request on that thread (or further delay its response).%
% however, the response
% must be for the thread matching the \CONTINUE\ invocation.%
\footnote{There are restrictions on how a driver can choose arguments
  to the step function.  We assume, for example, that
  it passes a \CONTINUE\ invocation for thread $t$
  if and only if $t$ has an outstanding request.
  Furthermore, since implementations are functions, they must be
  deterministic. We could model implementations instead as relations,
  allowing non-determinism, though this would complicate later arguments
  somewhat.}
%
% E is not sure this is still important so going to remove it for now
% \XXX[AC]{This gives implementations the ability to force sequential
% histories.  As we discussed, this is actually okay because this includes
% what real implementations can really do and so our proof includes
% reality, but that's not something I would expect a reader to put
% together.}
%\XXX[AC]{When does an implementation get invoked with \CONTINUE?  Is this
%non-deterministic?  Does it have to be fair?}

An implementation \emph{generates} a history when calls to the
implementation (perhaps including \CONTINUE\ invocations)
could potentially produce the corresponding history.
For example, this sequence
shows an implementation $m$ generating a history
\scpline{\scpi{A}{1} \scpi{B}{2} \scpr{B}{2} \scpr{A}{1}}:

\begin{CompactItemize}
\item $m(s_0, \text{\scpline{\scpi{A}{1}}}) = \langle s_1, \scpt{\CONTINUE}{1} \rangle$
\item $m(s_1, \text{\scpline{\scpi{B}{2}}}) = \langle s_2, \scpt{\CONTINUE}{2} \rangle$
\item $m(s_2, \scpt{\CONTINUE}{1}) = \langle s_3, \scpt{\CONTINUE}{1} \rangle$
\item $m(s_3, \scpt{\CONTINUE}{2}) = \langle s_4, \text{\scpline{\scpr{B}{2}}}\rangle$
\item $m(s_4, \scpt{\CONTINUE}{1}) = \langle s_5, \text{\scpline{\scpr{A}{1}}}\rangle$
\end{CompactItemize}

\noindent The state is threaded from step to step;
invocations appear as arguments and responses as
return values. The generated history consists of the invocations
and responses, in order, with \CONTINUE{}s removed.

An implementation $m$ is \emph{correct} for some specification $\SPEC$
when the responses it generates are always allowed by the specification.
Specifically, let $H$ be a valid history that can be generated by $m$.
We say that $m$ is correct when every such $H$ is in $\SPEC$.
% Specifically, assume $H \in \SPEC$ is a valid history and
% $r$ is a response where $m$ can generate $H \HCONCAT r$.
% We say that $m$ is correct when for any such $H$ and $r$, $H
% \HCONCAT r \in \SPEC$.
Note that a correct implementation need not be
capable of generating
every possible legal response or every possible history in $\SPEC$;
it's just that every response it does
generate is legal.

To reason about conflict freedom, we must peek into
implementation states, identify reads and writes, and check for access
conflicts.
%
Let each state $s \in S$ be a tuple $\tup{s.0, \dots, s.j}$, and let
%
$\tupleadj{s}{i}{x}$ indicate component
replacement: $\tupleadj{s}{i}{x} = \tup{s.0,\dots,s.(i-1),x,s.(i+1),\dots,s.j}$.
%
Now consider an implementation step $m(s,a) = \tup{s', r}$.
%
This step \emph{writes} state component $i$
when $s.i \neq s'.i$.
%
It \emph{reads} state component $i$ when $s.i$ may affect the
step's behavior; that is, when for some $y$,
%
\[m(\tupleadj{s}{i}{y},a) \neq \tup{\tupleadj{s'}{i}{y}, r}.\]
%
Two implementation steps have an \emph{access conflict} when they are on
different threads and one writes a state component that the other either
writes or reads.
%
This notion of access conflicts maps directly onto the read and write access
conflicts on real shared-memory machines explored in
\cref{sec:scalability}.
%
A set of implementation steps is \emph{conflict-free}
when no pair of steps in the set has an access conflict; that is, no
thread's steps read or write a state component written by another
thread's steps.
% Since modern MESI-based
% cache-coherent machines
% usually provide good scalability on conflict-free access patterns,
% we can loosely say that a conflict-free set of implementation steps
% ``scales.''


\subsection{Rule}

We can now formally state the scalable commutativity rule.
%
Assume a specification $\SPEC$ with a correct reference implementation
$\REFIMP$.
%
Consider a history $H = \HX \HCONCAT \HY$ where $\HY$ \SIM-commutes in $H$,
and where $\REFIMP$ can generate $H$.
%
Then there exists a correct implementation $m$ of $\SPEC$ whose steps in
the $\HY$ region of $H$ are conflict-free.
%
Empirically, conflict-free operations scale linearly on modern
multicore hardware, so, given reasonable workload assumptions,
$m$ scales in the $\HY$ region of $H$.

% \XXX[rtm]{``the ... $\HY$ region'' seems to imply that $m$ must
% generate the same B as $M$.
% is that generally true? what if the specification allows more
% than one response to an invocation? what if $m$ delays responses
% a different amount than $M$? maybe we mean ``there exists an $m$
% that generates the same $\HY$ as $M$ and is conflict-free.''}

% \XXX[E]{In fact the construction does generate the same results as those
% in $\HY$, for any ordering of the invocations of $\HY$. And this is true
% even if the TRUE implementation, given a different order of invocations
% than the original $\HY$ order, WOULD GENERATE DIFFERENT RESULTS. This is
% important; it's what I'd like interface-based to mean.}

% \XXX[AC]{The construction works not just for $\HX \HCONCAT \HY$, but for
% any $\HX \HCONCAT \HY'$ where $\HY'$ is a reordering of $\HY$.  Indeed
% this has to be
% the case, since, by its very nature, the construction can't tell the
% difference, but we write things as if it has to be $\HY$.  Should we be
% clearer that the construction is conflict-free in any $\HY'$?}


\subsection{Example}
\label{sec:rule:rc-example}

Before we turn to why the scalable commutativity rule is true, we'll
first illustrate how the rule helps designers think about interfaces
and implementations, using reference counters as a case study.

In its simplest form, a reference counter has two operations,
\code{inc} and \code{dec}, which respectively increment and decrement
the value of the counter and return its new value.  We'll also
consider a third operation, \code{iszero}, which returns whether the
reference count is zero.  Together, these operations and their
behavior define a reference counter specification $\SPECRC$.
$\SPECRC$ has a simple reference implementation using a shared
counter, which we can represent formally as
%
\begin{align*}
  \MRC(s, \code{inc}) & \equiv \tup<s+1, s+1> &
  \MRC(s, \code{dec}) & \equiv \tup<s-1, s-1> &
  \MRC(s, \code{iszero}) & \equiv \tup<s, s = 0>
\end{align*}

\newcommand\HAB{H_{\text{\sf AB}}}
\newcommand\HABC{H_{\text{\sf ABC}}}
\newcommand\HBC{H_{\text{\sf BC}}}
\newcommand\HCD{H_{\text{\sf CD}}}

\noindent
Consider a reference counter that starts with a value of $2$ and the
history
%
\[H =
  [\underbrace{
    \scpline{\scpi{A}{1}}=\code{iszero()}, \scpline{\scpr{A}{1}}=\code{false},
    \scpline{\scpi{B}{2}}=\code{iszero()}, \scpline{\scpr{B}{2}}=\code{false}}_{\HAB},
   \underbrace{
    \scpline{\scpi{C}{3}}=\code{dec()}, \scpline{\scpr{C}{3}}=1,
    \scpline{\scpi{D}{1}}=\code{dec()}, \scpline{\scpr{D}{1}}=0}_{\HCD}]
\]
%
The region $\HAB$ \SIM commutes in $H$.  Thus, by the rule, there is
an implementation of $\SPECRC$ that is conflict-free for $\HAB$.  In
fact, this is already true of the shared counter reference
implementation $\MRC$ because \code{iszero} reads the state, but does
not change it.

$\HCD$ does not \SIM commute in $H$, and therefore the rule does not
apply (indeed, no correct implementation can be conflict-free for
$\HCD$).  However, the rule does suggest a direction: if we modify the
specification so that \code{dec} (and \code{inc}) return nothing, then
these modified operations \emph{do} commute (more precisely: any
region consisting exclusively of these operations commutes in any
history).  With this modified specification, $\SPECRC'$, the caller
must invoke \code{iszero} to detect when the object is no longer
referenced, but in many cases this delayed zero detection is
acceptable and represents a desirable trade-off.

The equivalent history with this modified specification is
%
\[H' = [
   \rlap{$\overbrace{\phantom{
         \scpline{\scpi{A}{1}}=\code{iszero()},
         \scpline{\scpr{A}{1}}=\code{false},
         \scpline{\scpi{B}{2}}=\code{iszero()},
         \scpline{\scpr{B}{2}}=\code{false},
         \scpline{\scpi{C}{3}}=\code{dec()}, \scpline{\scpr{C}{3}}}}^{\HABC'}$}
   \underbrace{
    \scpline{\scpi{A}{1}}=\code{iszero()}, \scpline{\scpr{A}{1}}=\code{false},
    \scpline{\scpi{B}{2}}=\code{iszero()}, \scpline{\scpr{B}{2}}=\code{false}}_{\HAB'},
   \underbrace{
    \scpline{\scpi{C}{3}}=\code{dec()}, \scpline{\scpr{C}{3}},
    \scpline{\scpi{D}{1}}=\code{dec()}, \scpline{\scpr{D}{1}}}_{\HCD'}]
\]

Unlike $\HCD$, $\HCD'$ \SIM commutes.  And, accordingly, there is an
implementation of $\SPECRC'$ that is conflict-free for $\HCD'$: using
per-thread counters, each \code{dec} can modify its local counter,
while \code{iszero} sums the per-thread values.  Per-thread and
per-core sharding of data structures like this is a common and
long-standing pattern in scalable implementations.

The rule highlights at least one more opportunity in this history.
$\HABC'$ \emph{also} \SIM commutes (still assuming an initial count of
$2$).  However, the implementation given above for $\HCD'$ is
\emph{not} conflict-free for $\HABC'$ because $\scpline{\scpi{C}{3}}$
will write one component of the state that is read and summed by
$\scpline{\scpi{A}{1}}$ (and $\scpline{\scpi{B}{2}}$).  But, again,
there is a conflict-free implementation based on adding a Boolean
\code{iszero} snapshot to the state.  \code{iszero} simply returns
this snapshot.  When \code{dec}'s per-thread value reaches zero, it
can read and sum all per-thread values and update the \code{iszero}
snapshot if necessary.

These two implementations of $\SPECRC'$ are fundamentally different.
Which is most desirable depends on whether the workload is expected to
be write-heavy (mostly \code{inc} and \code{dec}) or read-heavy
(mostly \code{iszero}).  Thus an implementer must determine what
opportunities to scale exist, decide which are likely to be the most
valuable, and choose the implementation that scales in those
situations.

In \cref{sec:sv6:refcache}, we'll return to the topic of reference
counters when we describe \refcache, a practical and broadly
conflict-free implementation of a \emph{lazy reference counter}
similar to $\SPECRC'$.


\subsection{Proof}

The implementations of the reference counter example were derived by
hand, but a general, constructive proof for the scalable commutativity
rule is possible.
%
The construction builds a conflict-free implementation $m$ from an
arbitrary reference implementation $\REFIMP$ and history $H = \HX
\HCONCAT \HY$.
%
% Given a reference implementation $\REFIMP$ and history $H = \HX
% \HCONCAT \HY$ where $\HY$ \SIM commutes in $H$, the construction
% builds a new implementation $m$ that is conflict-free for $\HY$.
%
The constructed implementation emulates the reference implementation and
is thus correct for any history. Its \emph{performance}
properties, however, are specialized for $H$. For
any history $\HX\HCONCAT P$ where $P$ is a prefix of a
reordering of $\HY$, the constructed implementation's steps in $P$
are conflict-free. That is, within the \SIM-commutative
region, $m$ scales.


\begin{figure}
\begin{obeylines}
\begin{obeyspaces}
\(\NSIMP(s, a) \equiv\)
~~~If \(\HEAD(s.h) = a\):
~~~    \(r \gets \CONTINUE\)
~~~else if \(a = \CONTINUE\) and \(\HEAD(s.h)\) is a response
~~~              and \(\THREAD(\HEAD(s.h)) = \THREAD(a)\):
~~~    \(r \gets \HEAD(s.h)\)   \COMMENT{replay $s.h$}
~~~else if \(s.h \neq \EMULATE\):   \COMMENT{$H$ complete or input diverged}
~~~    \(H' \gets \text{an invocation sequence consistent with \(s.h\)}\)
~~~    For each invocation \(x\) in \(H'\):
~~~        \(\tup{s.\V{refstate}, \_} \gets \REFIMP(s.\V{refstate}, x)\)
~~~    \(s.h \gets \EMULATE\)   \COMMENT{switch to emulation mode}
~~~If \(s.h = \EMULATE\):
~~~    \(\tup{s.\V{refstate}, r} \gets \REFIMP(s.\V{refstate}, a)\)
~~~else:                 \COMMENT{replay mode}
~~~    \(s.h \gets \text{tail}(s.h)\)
~~~Return \(\tup{s, r}\)
\end{obeyspaces}
\end{obeylines}
\rule{\columnwidth}{0.5pt}
\vspace{-\baselineskip}
\caption{Constructed \emph{non-scalable} implementation $\NSIMP$ for
  history $H$ and
  reference implementation $M$.}
\label{fig:nonscalablesim}
\end{figure}

% Keep an index in $H$ instead of a mutable $s.h$?  Explicitly represent
% emulation mode in that index?  Messy with \END\ and per-thread $s.h$ in
% $m$.  Explicitly represent mode of $m$?  Could have a single commute
% flag in $m$, set when you reach the end of $A$.

To understand the construction, it helps to first imagine constructing a
\emph{non-scalable} implementation $\NSIMP$ from the reference $M$.
%
This non-scalable implementation begins in \emph{replay mode}.
%
While the input invocations match $H$, $\NSIMP$ responds exactly according to
$H$, without invoking the reference.
%
When the input invocations diverge from $H$, however, $\NSIMP$ no
longer knows how to respond, so it enters \emph{emulation mode}.
%
This requires feeding $M$ all previously received invocations to
prepare its state.

A state $s$ for $\NSIMP$ contains two components.
%
First, $s.h$ holds either the portion of $H$ that remains to be replayed
or \EMULATE, which denotes emulation mode.
It is initialized to $H$.
%
Second, $s.\V{refstate}$ is the state of the reference
implementation, and is initialized accordingly.
%
\Cref{fig:nonscalablesim} shows how the simulated implementation
works.
%
We make several simplifying assumptions, including that $\NSIMP$
receives \CONTINUE\ invocations in a restricted way; these assumptions aren't
critical for the argument.
%
One line requires expansion, namely the choice of $H'$ ``consistent
with \(s.h\)'' when the input sequence diverges.
%
This step calculates the prefix of $H$ up to, but not including, $s.h$;
excludes responses; and adds \CONTINUE\ invocations as appropriate.

This implementation is correct---its responses for any history
always match those from the reference implementation.
%
But it isn't conflict-free.
%
In replay mode, any two steps of $\NSIMP$ conflict on accessing
$s.h$. These accesses track which invocations
have occurred; without them it would be impossible to later
initialize the state of $M$.
%
And this is where commutativity comes in.
%
The action order in a \SIM-commutative region doesn't matter by
definition.
%
Since the specification doesn't distinguish among orders, it
is safe to initialize the reference implementation with the commutative
actions \emph{in a different order than they were received}.
%
All future responses will still be valid according to the specification.

\begin{figure}
\begin{obeylines}
\begin{obeyspaces}
\(m(s, a) \equiv\)
~~~\(t \gets \THREAD(a)\)
~~~If \(\HEAD(s.h[t]) = \COMMUTE\):  \COMMENT{enter conflict-free mode}
~~~    \(s.\V{commute}[t] \gets \TRUE\);~ \(s.h[t] \gets \TAIL(s.h[t])\)
~~~If \(\HEAD(s.h[t]) = a\):
~~~    \(r \gets \CONTINUE\)
~~~else if \(a = \CONTINUE\) and \(\HEAD(s.h[t])\) is a response
~~~              and \(\THREAD(\HEAD(s.h[t])) = t\):
~~~    \(r \gets \HEAD(s.h[t])\)   \COMMENT{replay $s.h$}
~~~else if \(s.h[t] \neq \EMULATE\):   \COMMENT{$H$ complete/input diverged}
~~~    \(H' \gets \text{an invocation sequence consistent with \(s.h[\ast]\)}\)
~~~    For each invocation \(x\) in \(H'\):
~~~        \(\tup{s.\V{refstate}, \_} \gets \REFIMP(s.\V{refstate}, x)\)
~~~    \(s.h[u] \gets \EMULATE\) for each thread \(u\)
~~~If \(s.h[t] = \EMULATE\):
~~~    \(\tup{s.\V{refstate}, r} \gets \REFIMP(s.\V{refstate}, a)\)
~~~else if \(s.\V{commute}[t]\):   \COMMENT{conflict-free mode}
~~~    \(s.h[t] \gets \text{tail}(s.h[t])\)
~~~else:   \COMMENT{replay mode}
~~~    \(s.h[u] \gets \text{tail}(s.h[u])\) for each thread \(u\)
~~~Return \(\tup{s, r}\)
\end{obeyspaces}
\end{obeylines}
\rule{\columnwidth}{0.5pt}
\vspace{-\baselineskip}
\caption{Constructed scalable implementation $m$ for history $H$ and
  reference implementation $M$.}
\label{fig:scalablesim}
\end{figure}

\Cref{fig:scalablesim} shows the construction of $m$, a
version of $M$ that scales over $\HY$ in $H = \HX\HCONCAT \HY$.
%
$m$ is similar to $\NSIMP$, but extends it with a \emph{conflict-free
  mode} used to execute actions in $\HY$.
%
Its state is as follows:

\begin{CompactItemize}
\item $s.h[t]$---a per-thread history. Initialized to
  $\HX\HCONCAT\COMMUTE\HCONCAT(\HRESTRICT{\HY}{t})$, where the special
  \COMMUTE\ action indicates the commutative region has begun.
\item $s.\V{commute}[t]$---a per-thread flag indicating whether the
  commutative region has been reached. Initialized to \FALSE.
\item $s.\V{refstate}$---the reference implementation's state.
\end{CompactItemize}

\noindent%
Each step of $m$ in the commutative region \emph{accesses
only state components specific to the invoking thread}.
%
This means that any two steps in the commutative region are
conflict-free, and the scalable commutativity rule is proved.
%
The construction uses \SIM\ commutativity when initializing the
reference implementation's state via $H'$.
%
If the observed invocations diverge before the commutative region, then
just as in $\NSIMP$, $H'$ will exactly equal the observed invocations.
%
If the observed invocations diverge in or after the commutative region,
however, there's not enough information to recover the order of
invocations. (The $s.h[t]$ components track which invocations have
happened per thread, but not the order of those invocations between
threads.) Therefore, $H'$ might reorder the invocations in $\HY$.
%
\SIM\ commutativity guarantees that replaying $H'$ will nevertheless produce
results indistinguishable from those of the actual invocation order,
even if the execution
diverges \emph{within} the commutative region.\footnote{%
  We effectively have assumed that $M$, the reference
  implementation, produces the same results for any reordering of the
  commutative region. This is stricter than \SIM\ commutativity, which
  places requirements on the {specification}, not the
  implementation. We also assumed that $M$ is indifferent to the
  placement of \CONTINUE\ invocations in
  the input history.  Neither of these restrictions is fundamental, however.  If
  during replay $M$ produces responses that are inconsistent with the
  desired results, $m$ could throw away $M$'s state, produce a new $H'$
  with different \CONTINUE\ invocations and/or commutative region ordering,
  and try again.
  This procedure must eventually succeed and does not change the
  conflict-freedom of $m$ in the commutative region.}

\begin{comment}
\begin{figure*}
% A serial history
(a) \scpline{\scpi{A}{1}
\scpr{A}{1}
\scpi{B}{1}
\scpr{B}{1}
\scpi{C}{1}
\scpr{C}{1}
\scpi{D}{1}
\scpr{D}{1}
\scpi{E}{1}
\scpr{E}{1}
\scpi{F}{1}
\scpr{F}{1}
\scpi{G}{1}
\scpr{G}{1}} \dots

\vskip5pt
% A three-threaded history
\def\threethreadedhistory{%
\scpi{A}{1}
\scpi{B}{3}
\scpi{C}{2}
\scpr{A}{1}
\scpr{C}{2}
\scpr{B}{3}
\scpi{D}{1}
\scpr{D}{1}
\scpi{E}{3}
\scpr{E}{3}
\scpi{F}{2}
\scpi{G}{3}
\scpi{H}{1}
\scpr{F}{2}
\scpr{H}{1}
\scpr{G}{3}
\scpi{I}{2}
\scpr{I}{2}
\scpi{J}{2}
\scpi{K}{1}
\scpr{J}{2}
\scpi{L}{3}
\scpr{K}{1}
\scpi{M}{1}
\scpr{L}{3}
\scpr{M}{1}}
(b) \scpline{\threethreadedhistory} \dots

\vskip5pt
\begin{tabular}{@{}l@{~}l@{}}
(c) & \scplinerestrict{1}{\threethreadedhistory}\\
& \scplinerestrict{2}{\threethreadedhistory}\\
& \scplinerestrict{3}{\threethreadedhistory}
\end{tabular}

\vskip5pt
(d) \scpline{\scpix{A}{3}
\scpix{B}{1}
\scprx{A}{3}
\scpix{C}{3}
\scprx{C}{3}
\scpix{D}{2}
\scpix{E}{3}
\scprx{B}{1}
\scprx{E}{3}
\scprx{D}{2}
\scpi{F}{3}
\scpi{G}{1}
\scpi{H}{2}
\scpr{G}{1}
\scpr{F}{3}
\scpr{H}{2}
\scpi{I}{1}
\scpi{J}{2}
\scpr{J}{2}
\scpix{K}{3}
\scprx{I}{1}
\scprx{K}{3}
\scpix{L}{3}
\scpix{M}{2}
\scprx{L}{3}
\scpix{N}{3}
\scprx{M}{2}
} \dots

\def\commutativeregiona{%
\scpi{F}{3}
\scpi{G}{1}
\scpi{H}{2}
\scpr{G}{1}
\scpr{F}{3}
\scpr{H}{2}
\scpi{I}{1}
\scpi{J}{2}
\scpr{J}{2}}

\def\commutativeregionb{%
\scpi{H}{2}
\scpi{F}{3}
\scpr{H}{2}
\scpi{G}{1}
\scpi{J}{2}
\scpr{F}{3}
\scpr{G}{1}
\scpr{J}{2}
\scpi{I}{1}}

\def\commutativeregionc{%
\scpi{G}{1}
\scpi{H}{2}
\scpi{F}{3}
\scpr{H}{2}
\scpr{G}{1}
\scpi{I}{1}}


\vskip5pt
\begin{tabular}{@{}l@{~}l@{\qquad\qquad}l@{\qquad\qquad}l@{}}
(e) & \scpline{\commutativeregiona}
   & \scpline{\commutativeregionb}
   & \scpline{\commutativeregionc} \\
\noalign{\vskip3pt}
   & \scplinerestrict{1}{\commutativeregiona}
   & \scplinerestrict{1}{\commutativeregionb}
   & \scplinerestrict{1}{\commutativeregionc} \\
   & \scplinerestrict{2}{\commutativeregiona}
   & \scplinerestrict{2}{\commutativeregionb}
   & \scplinerestrict{2}{\commutativeregionc~\scpicut{J}{2}~\scprcut{J}{2}} \\
   & \scplinerestrict{3}{\commutativeregiona}
   & \scplinerestrict{3}{\commutativeregionb}
   & \scplinerestrict{3}{\commutativeregionc~\scprcut{F}{3}} \\
\end{tabular}

\caption{\textbf{(a)} A serial, single-threaded history. Each invocation (filled
  circle) is immediately followed by its response (open circle).
%
  \textbf{(b)} A three-thread history. Colors indicate different threads.
%
  \textbf{(c)} The thread-restricted subhistories of (b). Each is
  serial.
%
  \textbf{(d)} A three-thread history with a commutative region. The
  commutative region is highlighted.
%
  \textbf{(e)} Three interleavings of the commutative region.
%
  \protect\XXX[E]{This figure is currently unreferenced, leaving it in case
  others think it useful.}~
}
\end{figure*}
\end{comment}

\subsection{Discussion}

The rule and proof construction push state and
history dependence to an extreme: the proof construction is specialized
for a \emph{single} commutative region.
%
This can be mitigated by repeated application of the construction to
build an
implementation that scales over multiple commutative regions in a
history, or for the union of many histories.%
%
\footnote{This is possible because, once the constructed machine
  leaves the specialized region, it passes invocations directly to the
  reference and has the same conflict-freedom properties as the
  reference.}
%
Nevertheless, the implementation constructed by the proof is
impractical and real implementations achieve broad scalability using
different techniques, such as the ones this dissertation explores in
\cref{sec:sv6}.

We believe such broad implementation scalability is made easier by
broadly commutative interfaces.
%
In broadly commutative interfaces, the arguments and system states for
which a set of operations
commutes often collapse into
fairly well-defined classes (e.g., file creation might
commute whenever the containing directories are different).
%
In practice, implementations scale for whole classes of states and
arguments, not just for specific histories.

On the other hand, there can be limitations on how broadly an
implementation can scale.
%
It is sometimes the case that a set of operations
commutes in more than one class of situation,
% and while there exist scalable implementations for each class, 
but no
single implementation can scale for all classes.
%
The reference counter example in \cref{sec:rule:rc-example} hinted at
this when we constructed several possible implementations for
different situations, but never arrived at a broadly conflict-free
one.
%
As an example that's easier to reason about,
consider an interface with two calls:
\code{put($x$)} records a sample with value $x$, and
\code{max()} returns the maximum sample recorded so far (or \code{0}).
Suppose
%
\[H = [
   \rlap{$\overbrace{\phantom{
         \scpline{\scpi{A}{1}}=\code{put(1)}, \scpline{\scpr{A}{1}},
         \scpline{\scpi{B}{2}}=\code{put(1)}, \scpline{\scpr{B}{2}}}}^{\HAB}$}
   \scpline{\scpi{A}{1}}=\code{put(1)}, \scpline{\scpr{A}{1}},
   \underbrace{
     \scpline{\scpi{B}{2}}=\code{put(1)}, \scpline{\scpr{B}{2}},
     \scpline{\scpi{C}{3}}=\code{max()}, \scpline{\scpr{C}{3}}=1}_{\HBC}].
\]
%
Both $\HAB$ and $\HBC$ \SIM commute in $H$, but $H$ overall is not \SIM
commutative.
%
An implementation could store per-thread maxima reconciled by
\code{max} and be conflict-free for $\HAB$.  Alternatively, it could use a
global maximum that \code{put} checked before writing.  This
is conflict-free for $\HBC$.
%Symmetric cases hold in the history $\scpline{\scpir{B}{2} \scpir{A}{1}
%  \scpir{C}{3}}$. 
%% E: I am happy to ignore this nit; not sure it's relevant.
%
But no correct implementation can be conflict-free across all of $H$.
Since $\HAB$ and $\HBC$ together span $H$, that means no single
implementation can be conflict-free for \emph{both} $\HAB$ and $\HBC$.
%
% In the
% end, a system designer must decide which situations involving
% commutative operations are most important, and find practical
% implementation strategies that scale in those situations.
%
% \XXX[AC]{Already sort of made this point in example, but without a
%   proof.  Maybe keep proof here, but with reference to that example:
%   %
%   In section X, we discussed several implementations of a reference
%   counter implementation, but never developed a broadly conflict-free
%   one.  In fact, this was not merely limited by our imagination: some
%   interfaces have multiple commutative classes, but no single
%   implementation scales for all cases.}

In our experience, real-world interface operations rarely demonstrate
such mutually exclusive implementation choices.  For example, the
POSIX implementation in \cref{sec:sv6} scales quite broadly, with only
a handful of cases that would require incompatible implementations.

We hope to further explore this gap between the specificity of the
formalized scalable commutativity rule and the generality of practical
implementations.
%
We'll return to this question and several other avenues for future
work in \cref{sec:future-work}.
%
However, as the rest of this dissertation shows, the rule is already
an effective guideline for achieving practical scalability.


% The scalable commutativity rule shows that \SIM-commutative regions
% have conflict-free implementations.
% %
% It does not show the converse, however:
% commutativity \emph{suffices} for conflict-free accesses,
% but it may not be \emph{necessary}.
% %
% Some non-commutative interfaces may have scalable
% implementations---for instance, on machines that
% offer scalable access to strictly increasing sources of time, or when
% the core interconnect allows certain communication patterns to scale.
% %
% Furthermore, as we showed in \cref{sec:scalability}, some conflict-free
% access patterns don't scale on real
% machines.
% %
% We hope to investigate these problems in the future, but as the rest
% of this dissertation shows,
% the rule is already a good guideline for achieving practical
% scalability.


% The rest of this paper gives examples of how the rule guided
% us toward missed opportunities for scalability, and inspired new
% scalable implementation strategies.

%  LocalWords:  reorderings
