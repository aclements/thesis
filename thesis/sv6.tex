\section{Achieving conflict-freedom in POSIX}
\label{sec:sv6}

\XXX[STATUS]{Draft v2 ready (have unapplied edits from Eddie).  Split
  from ``Finding scalability opportunities'' in SOSP.  Copied and
  reworked \refcache and \vm sections from EuroSys.  New intros for
  all subsections.  Applied Frans' edits from init-154-6dbae76 (with
  one outstanding bigger change to \fs section).}

Given that many commutative operations are not conflict-free in Linux,
is it feasible to build file system and virtual memory systems that
do achieve conflict-freedom?
%
To answer this
question, we designed and implemented a \code{ramfs}-like in-memory
file system called \fs and a virtual memory system called RadixVM for
\sys, our research kernel based on xv6~\cite{xv6}.
%
Although it is in principle possible to make the same changes in Linux,
we chose not to implement \fs in Linux because \fs's design
would have required extensive changes throughout the Linux kernel.
%
The designs of both RadixVM and \fs were guided by the
commutativity rule.  For \fs, we relied heavily on \tool throughout
development to guide its design and identify sharing problems in its
implementation.  RadixVM
was built prior to
\tool, but was guided by manual reasoning about commutativity and
conflicts, which we later validated using \tool.

\begin{figure*}
\small
\centering
\inputnodraft{figures/testcases-sv6}
\caption{Conflict-freedom of commutative system call pairs in \sys.}
\label{fig:testcase-breakdown-sv6}
\end{figure*}

\Cref{fig:testcase-breakdown-sv6} shows the result of applying \tool
to \sys.  In contrast with Linux, \sys is conflict-free for nearly
every commutative test case.  The rest of \thiscref{sec:sv6} explores the
design of \sys and answers the following questions:

\begin{CompactItemize}

\item What techniques are necessary to achieve conflict-freedom for
      cases where current file and virtual memory systems are not?

\item What situations might be too difficult or impractical to
      make conflict-free, despite being commutative?

\end{CompactItemize}

\Thiscref{sec:sv6} starts with the design of Refcache, a scalable reference
counting mechanism used throughout \sys.  It then covers the designs
of RadixVM and \fs.  Finally, it discusses operations that are
difficult to make conflict-free without sacrificing other practical
concerns.

\XXX[AC]{I think we need to be clear that none of these subsystems
  100\% follows the rule, but that that's okay from an engineering
  standpoint.  Work this in when I make this chapter more broadly
  about \sys.  E.g.,

  Like \refcache, \vm sacrifices strict adherence to the scalable
  commutativity rule in the interest of practical constraints on
  memory consumption and sequential performance.  Complex software
  systems inevitably involve conflicting requirements and scalability
  is no different.  However, in designing \vm, the presence of the
  rule forced us to explicitly recognize, evaluate, and justify where
  we made such trade-offs.}

\input{sv6-refcache}

\input{sv6-radixvm}

\subsection{\fs: Conflict-free file system operations}

\XXX[FK/AC]{Make this more like \vm section.  Lead with operations and
  their rough commutativity.  Since the high-level structure is much
  more like a conventional VFS than \vm is like a convention VM, say
  that and then explain some key detail (probably something involving
  hash tables).  E.g., how the inode cache works.  (See FK edits for
  init-154-6dbae76)}

\fs encompasses \sys's unified buffer cache and VFS layers, providing
operations such as \code{read}, \code{write}, \code{open}, and
\code{unlink}.  We focused on the VFS and buffer cache layers because
these are the common denominators of all file systems in a Unix
kernel.
%
In contrast with \vm,
\fs makes extensive use of well-known techniques for scalable
implementations, such as per-core resource
allocation, double-checked locking, lock-free readers using
RCU~\cite{rcu:linux},
and seqlocks~\cite[\S6]{lameter:linuxsync}.
%
\fs also employs \refcache for tracking both internal resources and
inode link counts.
%
\fs is also structured much like contemporary Unix VFS subsystems,
with inode and directory caches represented as concurrent hash tables
and per-file page caches.
%
What sets \fs apart is that the details of its implementation were
guided by the scalable commutativity rule and, in particular, by
\tool.
%
This led to several common design patterns, which we illustrate with
example test cases from \tool{}:
%
\XXX[AC]{\fs is more irregular than \vm, so \tool was more important.}


\paragraph{Layer scalability.}  \fs uses data structures that
themselves naturally satisfy the commutativity rule, such as linear
arrays, radix trees, and hash tables.  In
contrast with structures like balanced trees, these data
structures
typically share no cache lines when different elements are accessed
or modified.  For example, \fs stores the cached data pages for a given inode
using a radix tree, so that concurrent reads or writes to different
file pages scale, even in the presence of operations
extending or truncating the file.
% , as long as they don't access the part
% of the file that's being extended or truncated.
\tool led us to an additional benefit of this representation:
many operations also use this radix tree to determine if some offset
is within the file's bounds without reading the size and conflicting
with operations
that change the file's size.
%
For example, \code{pread} first probes this radix tree for the
requested read offset: if the offset is beyond the last page of the
file, it can return 0 immediately without reading (and potentially
conflicting on) the file size.

\XXX[FK]{``Defer work'' can be presented as dealing with
  non-commutative ops.}

\paragraph{Defer work.} Many \fs resources are shared,
such as file descriptions and inode objects, and must be freed when no
longer referenced.
Typically, kernels release resources immediately, but this requires
eagerly tracking references to resources, causing
commutative operations that access the same resource to conflict.  Where
releasing a resource is not time-sensitive, \fs
uses Refcache to batch reference count
reconciliation and zero detection.  This way, resources are eventually
released, but within each Refcache epoch commutative operations can be
conflict-free.

\XXX[AC]{Discuss crazy pipe hybrid reference counting scheme?}

Some resources are artificially scarce, such as inode numbers in a typical
Unix file system.  When a typical Unix file system runs out of free
inodes, it must reuse an inode from a recently deleted file.
%
This requires finding and garbage collecting unused inodes, which
induces conflicts.
%
However,
the POSIX interface does not require that inode numbers be reused, only
that the same inode number is not used for two files at once.  Thus,
\fs never reuses inode numbers.  Instead, inode numbers are
generated by a monotonically increasing per-core counter, concatenated
with the core number that allocated the inode.  This allows \fs to defer
inode garbage collection for longer periods of time, and enables
conflict-free and scalable
per-core inode allocation.


% \paragraph{Check before updating.}  Before updating any data structure,
% \fs first checks whether the data structure already contains the new
% value, and avoid any writes if so.  For example, the Linux file system
% always acquires a lock on an inode when truncating the file.  This means
% that concurrent truncate operations do not scale, even if the file
% is already empty.  \fs first checks the current length of the file,
% and avoids updating the length or acquiring any locks if the file is
% already at the right size.

% As another example, if one thread tries to create an existing file using
% \code{open(O_CREAT|O_EXCL)}, it should fail, but a na\"ive implementation
% might first acquire a lock to prepare for creating the file, and then
% check whether the file already exists.  This makes
% concurrent \code{open(O_CREAT|O_EXCL)} calls for an existing file name
% non-scalable.  \fs first checks whether the file already exists without
% modifying any cache lines, making these operations scale.

% \XXX[AC]{The above two examples are slightly off.  E.g., if I do two
% truncates and the first writes to the file length and the second reads
% that, that's sharing.  These are both idempotent updates, which is one
% of the few things we \emph{don't} do scalably.}

% As a final example, if two file names \code{a} and \code{b} point to the
% same inode, \code{rename(a, b)} should remove the directory entry for
% \code{a}, but it should not modify the directory entry for \code{b}, since
% it already points at the right inode.  By checking the directory
% entry for \code{b} before updating it, \fs allows \code{rename(a, b)}
% to scale with other operations that look up \code{b}.


\paragraph{Precede pessimism with optimism.} Many operations
in \fs have an optimistic check stage followed by a pessimistic update
stage, a generalized sort of double-checked locking.  The optimistic
stage checks conditions for the operation and returns immediately if
no updates are necessary (this is often the case for error returns,
but can also happen for success returns).  This stage does no writes
or locking, but because no updates are necessary, it is often easy to
make atomic.  If updates are necessary, the operation acquires
locks or uses lock-free protocols, re-verifies its conditions to
ensure atomicity of the update stage, and performs updates.  For
example, \code{lseek} first computes the new offset using a lock-free
read-only protocol and returns early if the new offset is invalid or
equal to the current offset.  Otherwise, \code{lseek} locks the file
offset and re-computes the new offset to ensure consistency.
%
In fact, \code{lseek} has surprisingly complex interactions with
system state and other operations, and arriving at a protocol that was
both correct and conflict-free in all commutative cases would have
been difficult without \tool.

\code{rename} is similar.  If two file names \code{a} and \code{b}
point to the
same inode, \code{rename(a, b)} should remove the directory entry for
\code{a}, but it does not need to modify the directory entry for
\code{b}, since
it already points at the right inode.  By checking the directory
entry for \code{b} before updating it, \code{rename(a, b)} avoids
conflicts with other operations that look up \code{b}.
%
As we saw in \cref{sec:topic:rename-conditions}, \code{rename} has
many surprising and subtle commutative cases and, much like
\code{lseek}, \tool was instrumental in helping us arrive at an
implementation that was conflict-free in these cases.


\paragraph{Don't read unless necessary.}  A common internal interface
in a file system implementation is a \code{namei} function that
checks whether a path name exists, and if so, returns the inode for
that path.
%
However, reading the inode is unnecessary
if the caller wants to know only whether a path name existed, such as
an \code{access(F_OK)} system call.  In particular, the \code{namei}
interface makes it impossible for concurrent \code{access(b, F_OK)}
and \code{rename(a, b)} operations to scale when \code{a} and \code{b}
point to different inodes, even though they commute.
\fs has a separate internal interface to check for existence of a
file name, without looking up the inode, which allows \code{access}
and \code{rename} to scale in such situations.


\subsection{Difficult-to-scale cases}

As \cref{fig:testcase-breakdown-sv6} illustrates, there are a few
(\pyexpr{mscan.xv6.shared} out of \pyexpr{mscan.ntestcases})
commutative test cases for
which \vm and \fs are not conflict-free.
%
The majority of these tests involve idempotent updates to internal
state, such as two \code{lseek} operations that both seek a file
descriptor to the same offset, or two anonymous \code{mmap} operations
with the same fixed base address and permissions.  While it is
possible implement these scalably, every implementation we considered
significantly impacted the performance of more common operations, so
we explicitly chose to favor common-case performance over total
scalability.  Even though we decided to forego scalability in these
cases, the commutativity rule and \tool forced us to consciously make
this trade-off.
%
\XXX[AC]{About 75\% are known idempotent.}

% Non-idempotent shared case list (incomplete):
% close_close_pe_5: Closing pipe writer (eager counting)
% close_read_pdc_0: Closing pipe writer, reading writer always EBADF
% close_write_pd8_0: Symmetric to close_read_pdc_0
% lseek_read_pad8_2: Reading nothing from two different offsets
% lseek_read_p8b6_3: Same as lseek_read_pad8_2
% mmap_mprotect_pf8_41: Making different read-only mappings read-only
%   (The mprotect is a no-op, but what it reads is modified)
% mmap_mprotect_pae_40: Same
% read_read_pce4_0: Two reads from a file full of zeroes
% read_write_pbb0_2: Reading nothing from different end-of-file offsets
% write_write_pff8_1: Writing to a pipe with no readers
%   (We could probably fix this one)
% write_write_pff8_2: Same
% write_write_pf78_1: Same

Other difficult-to-scale cases are more varied.  Several involve
reference counting of pipe file descriptors.  Closing the last file
descriptor for one end of a pipe must immediately affect the other
end; however, since there's generally no way to know a priori if a
\code{close} will close the pipe, a shared reference count is used in
some situations.  Other cases involve operations that return the same
result in either order, but for different reasons, such as two reads
from a file filled with identical bytes.

\XXX[AC]{fstest works around all radix tree expansion.  Is this
cheating?  That's actually an interesting case.}

\XXX[AC]{Summarize or something?}
