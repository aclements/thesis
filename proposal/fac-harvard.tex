\documentclass[11pt]{article}
\usepackage{url,mathptmx,times,verbatim}
\usepackage[hmargin=1in,vmargin=1in,letterpaper]{geometry}
\frenchspacing

\renewcommand{\thesection}{\Alph{section}}
\renewcommand{\thesubsection}{\Alph{section}.\alph{subsection}}

%\input{fonts.sty}

\begin{document}

\setcounter{section}{4}

\section*{Facilities \& Equipment: Harvard University}

\subsection*{Laboratory \& Computers}

Work will take place at a computer laboratory located at Harvard's
School of Engineering and Applied Sciences (SEAS), 33 Oxford St.,
Cambridge. It is equipped with office space and computers for the PI as
well as graduate students. Conference rooms and informal meeting areas
are also nearby. In addition, the school provides infrastructure such as
networking, printing, and administrative support for teaching and basic
research needs.

\subsection*{Computing@SEAS}

The Harvard School of Engineering and Applied Science (SEAS) provides
scientific computing services to the SEAS community through the
Computing@SEAS group (until recently Academic Computing). Computing@SEAS
maintains a variety of computing platforms to meet the research and
instructional needs of the School. These resources are shared among many
School users.

The School provides a 28 node commodity compute cluster platform,
with 244 Intel Xeon cores running at 2.33 GHz and 16 GB of RAM, and both
Inifiniband and Gigabit Ethernet interconnects. This system is backed by
a 24 TB GPFS scratch storage system.

Computing@SEAS also makes available a large memory host for
interactive use (with 8 Opteron cores at 3.0 GHz and 100 GB RAM) and an 8
core commodity virtual desktop server for development and productivity.

Special purpose hardware is also supported.
%
As a CUDA Center of Excellence, SEAS hosts an NVIDIA GPU computing
cluster, with 32 NVIDIA C1060 GPU cards, backed by a 16 compute nodes,
each with a 4 core, 2.33 GHz Intel Xeon processor, 16 GB RAM and both
Inifiniband and Gigabit Ethernet interconnects. In addition, for
development and testing an 8 core, 16 GB RAM host with 4 GPUs is
available. These systems are intended to support GPU computing.
%
To support large-scale parallel computation, the School hosts an IBM
Blue Gene/L supercomputer, with 4096 Power CPU cores running at 700 MHz
and 2 TB of total RAM, backed by 24 TB of GPFS file storage. This system
is intended for running parallel scalable MPI code, and access is
restricted to users with parallel MPI codes.

\end{document}

